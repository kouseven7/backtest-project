"""
Demo: Score Update Trigger System Integration
File: demo_score_update_trigger_integration.py
Description:
  2-3-3ã€Œã‚¹ã‚³ã‚¢ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãƒˆãƒªã‚¬ãƒ¼è¨­è¨ˆã€çµ±åˆãƒ‡ãƒ¢
  ScoreUpdateTriggerSystemã¨RealtimeUpdateEngineã®é€£æºå‹•ä½œç¢ºèª

Author: GitHub Copilot
Created: 2025-07-13
Modified: 2025-07-13
"""

import asyncio
import logging
import time
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from config.score_update_trigger_system import (
        ScoreUpdateTriggerSystem, TriggerType, TriggerPriority, TriggerCondition
    )
    from config.realtime_update_engine import (
        RealtimeUpdateEngine, UpdatePriority, UpdateRequest
    )
    from config.enhanced_score_history_manager import EnhancedScoreHistoryManager
    from config.strategy_scoring_model import StrategyScoreCalculator
except ImportError:
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    
    from config.score_update_trigger_system import (
        ScoreUpdateTriggerSystem, TriggerType, TriggerPriority, TriggerCondition
    )
    from config.realtime_update_engine import (
        RealtimeUpdateEngine, UpdatePriority, UpdateRequest
    )
    from config.enhanced_score_history_manager import EnhancedScoreHistoryManager
    from config.strategy_scoring_model import StrategyScoreCalculator

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('score_trigger_demo.log')
    ]
)

logger = logging.getLogger(__name__)

class TriggerSystemIntegrationDemo:
    """
    ã‚¹ã‚³ã‚¢ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãƒˆãƒªã‚¬ãƒ¼ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ‡ãƒ¢
    
    2-3-3ã§è¨­è¨ˆã—ãŸã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œã‚’å®Ÿæ¼”ï¼š
    1. ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶ã®è¨­å®šã¨ç›£è¦–
    2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ã‚¸ãƒ³ã¨ã®é€£æº
    3. å„ç¨®ãƒˆãƒªã‚¬ãƒ¼ã‚¿ã‚¤ãƒ—ã®å‹•ä½œç¢ºèª
    4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
    """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        # ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.enhanced_manager = None
        self.score_calculator = None
        self.trigger_system = None
        self.realtime_engine = None
        
        # ãƒ‡ãƒ¢çŠ¶æ…‹
        self.demo_results = {}
        self.demo_start_time = None
        
        logger.info("Trigger System Integration Demo initialized")
    
    async def run_demo(self):
        """ãƒ‡ãƒ¢å®Ÿè¡Œ"""
        self.demo_start_time = datetime.now()
        
        print("=" * 80)
        print("ğŸš€ Score Update Trigger System Integration Demo")
        print("=" * 80)
        print(f"Started at: {self.demo_start_time}")
        print()
        
        try:
            # 1. ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            await self._setup_systems()
            
            # 2. åŸºæœ¬ãƒˆãƒªã‚¬ãƒ¼å‹•ä½œç¢ºèª
            await self._demo_basic_triggers()
            
            # 3. é–¾å€¤ãƒ™ãƒ¼ã‚¹ãƒˆãƒªã‚¬ãƒ¼ç¢ºèª
            await self._demo_threshold_triggers()
            
            # 4. ãƒãƒƒãƒå‡¦ç†ç¢ºèª
            await self._demo_batch_processing()
            
            # 5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
            await self._demo_performance_test()
            
            # 6. ã‚¨ãƒ©ãƒ¼è€æ€§ç¢ºèª
            await self._demo_error_handling()
            
            # 7. çµæœã‚µãƒãƒªãƒ¼
            await self._display_demo_summary()
            
        except Exception as e:
            logger.error(f"Demo execution failed: {e}")
            print(f"âŒ Demo failed: {e}")
        
        finally:
            await self._cleanup_systems()
        
        print("\nâœ… Demo completed!")
    
    async def _setup_systems(self):
        """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ“‹ 1. Setting up systems...")
        
        try:
            # æ‹¡å¼µã‚¹ã‚³ã‚¢å±¥æ­´ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
            self.enhanced_manager = EnhancedScoreHistoryManager()
            print("   âœ“ Enhanced Score History Manager")
            
            # ã‚¹ã‚³ã‚¢è¨ˆç®—å™¨
            self.score_calculator = StrategyScoreCalculator()
            print("   âœ“ Strategy Score Calculator")
            
            # ãƒˆãƒªã‚¬ãƒ¼ã‚·ã‚¹ãƒ†ãƒ 
            self.trigger_system = ScoreUpdateTriggerSystem(
                enhanced_manager=self.enhanced_manager,
                score_calculator=self.score_calculator
            )
            print("   âœ“ Score Update Trigger System")
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ã‚¸ãƒ³
            self.realtime_engine = RealtimeUpdateEngine(
                trigger_system=self.trigger_system,
                enhanced_manager=self.enhanced_manager,
                score_calculator=self.score_calculator
            )
            print("   âœ“ Realtime Update Engine")
            
            # ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹
            self.trigger_system.start()
            print("   âœ“ Trigger system started")
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ã‚¸ãƒ³é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
            engine_task = asyncio.create_task(self.realtime_engine.start())
            await asyncio.sleep(1)  # é–‹å§‹å¾…æ©Ÿ
            print("   âœ“ Realtime engine started")
            
            # çµæœè¨˜éŒ²
            self.demo_results["setup_success"] = True
            
        except Exception as e:
            self.demo_results["setup_success"] = False
            self.demo_results["setup_error"] = str(e)
            raise
        
        print("   âœ… All systems ready!")
        print()
    
    async def _demo_basic_triggers(self):
        """åŸºæœ¬ãƒˆãƒªã‚¬ãƒ¼å‹•ä½œç¢ºèª"""
        print("ğŸ¯ 2. Basic trigger operations...")
        
        results = {}
        
        try:
            # æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼ãƒ†ã‚¹ãƒˆ
            print("   Testing manual triggers...")
            
            event_id = self.trigger_system.manual_trigger(
                strategy_name="demo_strategy_1",
                ticker="DEMO1",
                priority=TriggerPriority.HIGH,
                metadata={"test_type": "manual", "demo_step": "basic"}
            )
            
            results["manual_trigger_id"] = event_id
            print(f"   âœ“ Manual trigger queued: {event_id}")
            
            # å°‘ã—å¾…æ©Ÿã—ã¦ãƒˆãƒªã‚¬ãƒ¼å‡¦ç†ã‚’ç¢ºèª
            await asyncio.sleep(2)
            
            # ãƒˆãƒªã‚¬ãƒ¼çµ±è¨ˆç¢ºèª
            stats = self.trigger_system.get_trigger_statistics()
            results["initial_stats"] = stats
            print(f"   âœ“ Trigger stats: {stats['total_triggers']} total, {stats['queue_size']} queued")
            
            # ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶è¿½åŠ 
            print("   Adding custom trigger condition...")
            
            custom_condition = TriggerCondition(
                condition_id="demo_custom_trigger",
                trigger_type=TriggerType.EVENT_BASED,
                priority=TriggerPriority.MEDIUM,
                parameters={
                    "demo_parameter": True,
                    "sensitivity": 0.1
                },
                description="Demo custom trigger condition"
            )
            
            self.trigger_system.add_trigger_condition(custom_condition)
            results["custom_condition_added"] = True
            print("   âœ“ Custom trigger condition added")
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ã‚¸ãƒ³çŠ¶æ…‹ç¢ºèª
            engine_status = self.realtime_engine.get_engine_status()
            results["engine_status"] = engine_status
            print(f"   âœ“ Engine status: {engine_status['status']}, {engine_status['queue_size']} queued")
            
        except Exception as e:
            results["error"] = str(e)
            logger.error(f"Basic triggers demo failed: {e}")
        
        self.demo_results["basic_triggers"] = results
        print("   âœ… Basic trigger operations completed!")
        print()
    
    async def _demo_threshold_triggers(self):
        """é–¾å€¤ãƒ™ãƒ¼ã‚¹ãƒˆãƒªã‚¬ãƒ¼ç¢ºèª"""
        print("ğŸ“Š 3. Threshold-based triggers...")
        
        results = {}
        
        try:
            # é–¾å€¤ãƒˆãƒªã‚¬ãƒ¼æ¡ä»¶è¿½åŠ 
            print("   Setting up threshold trigger...")
            
            threshold_condition = TriggerCondition(
                condition_id="demo_threshold_trigger",
                trigger_type=TriggerType.THRESHOLD_BASED,
                priority=TriggerPriority.HIGH,
                parameters={
                    "score_change_threshold": 0.05,  # 5%å¤‰åŒ–ã§ç™ºç«
                    "monitoring_window_hours": 1,
                    "demo_mode": True
                },
                strategy_filter=["demo_strategy_2"],
                cooldown_seconds=30,  # 30ç§’ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³
                description="Demo threshold trigger (5% score change)"
            )
            
            self.trigger_system.add_trigger_condition(threshold_condition)
            results["threshold_condition_added"] = True
            print("   âœ“ Threshold trigger condition added (5% threshold)")
            
            # åˆæœŸã‚¹ã‚³ã‚¢ç”Ÿæˆï¼ˆã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ï¼‰
            print("   Generating initial scores...")
            
            initial_requests = []
            for i in range(3):
                request = UpdateRequest(
                    request_id=f"threshold_demo_init_{i}",
                    strategy_name="demo_strategy_2",
                    ticker=f"THRESH{i}",
                    trigger_type=TriggerType.MANUAL,
                    priority=3,
                    metadata={"phase": "initial", "iteration": i}
                )
                
                task_id = await self.realtime_engine.submit_update_request(
                    request, UpdatePriority.NORMAL
                )
                initial_requests.append(task_id)
            
            # åˆæœŸå‡¦ç†å®Œäº†å¾…æ©Ÿ
            await asyncio.sleep(3)
            results["initial_scores_generated"] = len(initial_requests)
            print(f"   âœ“ Generated {len(initial_requests)} initial scores")
            
            # é–¾å€¤ã‚’è¶…ãˆã‚‹å¤‰åŒ–ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            print("   Simulating significant score changes...")
            
            change_requests = []
            for i in range(2):
                request = UpdateRequest(
                    request_id=f"threshold_demo_change_{i}",
                    strategy_name="demo_strategy_2",
                    ticker=f"THRESH{i}",
                    trigger_type=TriggerType.MANUAL,
                    priority=1,  # é«˜å„ªå…ˆåº¦
                    metadata={
                        "phase": "significant_change",
                        "expected_threshold_trigger": True,
                        "iteration": i
                    }
                )
                
                task_id = await self.realtime_engine.submit_update_request(
                    request, UpdatePriority.REALTIME
                )
                change_requests.append(task_id)
            
            # å¤‰åŒ–å‡¦ç†å®Œäº†å¾…æ©Ÿ
            await asyncio.sleep(5)
            results["change_scores_generated"] = len(change_requests)
            print(f"   âœ“ Simulated {len(change_requests)} significant changes")
            
            # é–¾å€¤ãƒˆãƒªã‚¬ãƒ¼ã®å‹•ä½œç¢ºèª
            recent_events = self.trigger_system.get_recent_events(limit=10)
            threshold_events = [
                e for e in recent_events 
                if e.get("condition_id") == "demo_threshold_trigger"
            ]
            
            results["threshold_events_triggered"] = len(threshold_events)
            print(f"   âœ“ Threshold trigger fired {len(threshold_events)} times")
            
        except Exception as e:
            results["error"] = str(e)
            logger.error(f"Threshold triggers demo failed: {e}")
        
        self.demo_results["threshold_triggers"] = results
        print("   âœ… Threshold-based triggers completed!")
        print()
    
    async def _demo_batch_processing(self):
        """ãƒãƒƒãƒå‡¦ç†ç¢ºèª"""
        print("ğŸ”„ 4. Batch processing...")
        
        results = {}
        
        try:
            # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–é–‹å§‹å‰ã®çŠ¶æ…‹
            print("   Checking batch job capabilities...")
            
            initial_engine_status = self.realtime_engine.get_engine_status()
            results["initial_engine_status"] = initial_engine_status
            print(f"   âœ“ Initial queue size: {initial_engine_status['queue_size']}")
            
            # å¤§é‡ã®ä½å„ªå…ˆåº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ç”Ÿæˆ
            print("   Generating batch update requests...")
            
            batch_requests = []
            strategies = ["batch_strategy_1", "batch_strategy_2", "batch_strategy_3"]
            tickers = ["BATCH1", "BATCH2", "BATCH3", "BATCH4"]
            
            for strategy in strategies:
                for ticker in tickers:
                    request = UpdateRequest(
                        request_id=f"batch_{strategy}_{ticker}_{int(time.time())}",
                        strategy_name=strategy,
                        ticker=ticker,
                        trigger_type=TriggerType.TIME_BASED,
                        priority=5,  # ãƒãƒƒãƒå„ªå…ˆåº¦
                        metadata={
                            "batch_demo": True,
                            "batch_size": len(strategies) * len(tickers)
                        }
                    )
                    
                    task_id = await self.realtime_engine.submit_update_request(
                        request, UpdatePriority.BATCH
                    )
                    batch_requests.append(task_id)
            
            results["batch_requests_submitted"] = len(batch_requests)
            print(f"   âœ“ Submitted {len(batch_requests)} batch requests")
            
            # ãƒãƒƒãƒå‡¦ç†é€²æ—ç›£è¦–
            print("   Monitoring batch processing...")
            
            monitoring_start = time.time()
            batch_completed = False
            max_monitoring_time = 30  # æœ€å¤§30ç§’ç›£è¦–
            
            while time.time() - monitoring_start < max_monitoring_time and not batch_completed:
                await asyncio.sleep(2)
                
                current_status = self.realtime_engine.get_engine_status()
                
                print(f"   ğŸ“Š Queue: {current_status['queue_size']}, "
                      f"Completed: {current_status['successful_updates']}, "
                      f"Failed: {current_status['failed_updates']}")
                
                # ãƒãƒƒãƒå‡¦ç†å®Œäº†åˆ¤å®š
                if current_status['queue_size'] < 5:  # ã‚­ãƒ¥ãƒ¼ãŒã»ã¼ç©ºã«ãªã£ãŸ
                    batch_completed = True
            
            final_status = self.realtime_engine.get_engine_status()
            results["final_engine_status"] = final_status
            results["batch_processing_time"] = time.time() - monitoring_start
            results["batch_completed"] = batch_completed
            
            print(f"   âœ“ Batch processing {'completed' if batch_completed else 'monitored'}")
            print(f"   âœ“ Final queue size: {final_status['queue_size']}")
            print(f"   âœ“ Processing time: {results['batch_processing_time']:.2f}s")
            
        except Exception as e:
            results["error"] = str(e)
            logger.error(f"Batch processing demo failed: {e}")
        
        self.demo_results["batch_processing"] = results
        print("   âœ… Batch processing completed!")
        print()
    
    async def _demo_performance_test(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š"""
        print("âš¡ 5. Performance testing...")
        
        results = {}
        
        try:
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆè¨­å®š
            test_strategies = ["perf_strategy"]
            test_tickers = ["PERF1", "PERF2", "PERF3"]
            test_requests_per_ticker = 5
            
            total_requests = len(test_strategies) * len(test_tickers) * test_requests_per_ticker
            
            print(f"   Running performance test with {total_requests} requests...")
            
            # é–‹å§‹æ™‚åˆ»è¨˜éŒ²
            perf_start_time = time.time()
            initial_stats = self.realtime_engine.get_engine_status()
            
            # é«˜å„ªå…ˆåº¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å¤§é‡é€ä¿¡
            perf_requests = []
            
            for strategy in test_strategies:
                for ticker in test_tickers:
                    for i in range(test_requests_per_ticker):
                        request = UpdateRequest(
                            request_id=f"perf_{strategy}_{ticker}_{i}_{int(time.time())}",
                            strategy_name=strategy,
                            ticker=ticker,
                            trigger_type=TriggerType.MANUAL,
                            priority=2,  # é«˜å„ªå…ˆåº¦
                            metadata={
                                "performance_test": True,
                                "batch_number": i,
                                "expected_total": total_requests
                            }
                        )
                        
                        task_id = await self.realtime_engine.submit_update_request(
                            request, UpdatePriority.HIGH
                        )
                        perf_requests.append(task_id)
            
            print(f"   âœ“ Submitted {len(perf_requests)} performance test requests")
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
            monitoring_start = time.time()
            performance_completed = False
            
            while time.time() - monitoring_start < 20 and not performance_completed:  # 20ç§’ç›£è¦–
                await asyncio.sleep(1)
                
                current_stats = self.realtime_engine.get_engine_status()
                
                # å‡¦ç†å®Œäº†åˆ¤å®š
                completed_delta = (current_stats['successful_updates'] + current_stats['failed_updates']) - \
                                (initial_stats['successful_updates'] + initial_stats['failed_updates'])
                
                if completed_delta >= total_requests:
                    performance_completed = True
                
                print(f"   ğŸ“ˆ Processed: {completed_delta}/{total_requests}, "
                      f"Queue: {current_stats['queue_size']}, "
                      f"Avg time: {current_stats['average_processing_time']:.4f}s")
            
            # æœ€çµ‚çµæœ
            perf_end_time = time.time()
            final_stats = self.realtime_engine.get_engine_status()
            
            total_processing_time = perf_end_time - perf_start_time
            completed_requests = (final_stats['successful_updates'] + final_stats['failed_updates']) - \
                               (initial_stats['successful_updates'] + initial_stats['failed_updates'])
            
            throughput = completed_requests / total_processing_time if total_processing_time > 0 else 0
            
            results.update({
                "total_requests": total_requests,
                "completed_requests": completed_requests,
                "total_processing_time": total_processing_time,
                "throughput_per_second": throughput,
                "average_processing_time": final_stats['average_processing_time'],
                "performance_completed": performance_completed,
                "success_rate": (final_stats['successful_updates'] - initial_stats['successful_updates']) / completed_requests if completed_requests > 0 else 0
            })
            
            print(f"   âœ“ Performance test completed:")
            print(f"     - Total time: {total_processing_time:.2f}s")
            print(f"     - Throughput: {throughput:.2f} requests/sec")
            print(f"     - Avg processing: {final_stats['average_processing_time']:.4f}s")
            print(f"     - Success rate: {results['success_rate']*100:.1f}%")
            
        except Exception as e:
            results["error"] = str(e)
            logger.error(f"Performance test failed: {e}")
        
        self.demo_results["performance_test"] = results
        print("   âœ… Performance testing completed!")
        print()
    
    async def _demo_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼è€æ€§ç¢ºèª"""
        print("ğŸ›¡ï¸  6. Error handling and resilience...")
        
        results = {}
        
        try:
            # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            print("   Testing error resilience...")
            
            error_requests = []
            
            # 1. ç„¡åŠ¹ãªæˆ¦ç•¥å
            invalid_strategy_request = UpdateRequest(
                request_id="error_test_invalid_strategy",
                strategy_name="",  # ç©ºã®æˆ¦ç•¥å
                ticker="ERROR1",
                trigger_type=TriggerType.MANUAL,
                priority=2,
                metadata={"error_test": "invalid_strategy"}
            )
            
            task_id = await self.realtime_engine.submit_update_request(
                invalid_strategy_request, UpdatePriority.HIGH
            )
            error_requests.append(task_id)
            
            # 2. ç„¡åŠ¹ãªãƒ†ã‚£ãƒƒã‚«ãƒ¼
            invalid_ticker_request = UpdateRequest(
                request_id="error_test_invalid_ticker",
                strategy_name="error_test_strategy",
                ticker=None,  # None ãƒ†ã‚£ãƒƒã‚«ãƒ¼
                trigger_type=TriggerType.MANUAL,
                priority=2,
                metadata={"error_test": "invalid_ticker"}
            )
            
            # ã“ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã¯ãšãªã®ã§try-catchã§å‡¦ç†
            try:
                task_id = await self.realtime_engine.submit_update_request(
                    invalid_ticker_request, UpdatePriority.HIGH
                )
                error_requests.append(task_id)
            except Exception as e:
                print(f"   âœ“ Caught expected error for invalid ticker: {type(e).__name__}")
                results["invalid_ticker_error_caught"] = True
            
            # 3. å¤§é‡ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆè² è·ãƒ†ã‚¹ãƒˆï¼‰
            print("   Testing high load resilience...")
            
            load_test_start = time.time()
            concurrent_requests = []
            
            for i in range(20):  # 20å€‹ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                request = UpdateRequest(
                    request_id=f"load_test_{i}",
                    strategy_name="load_test_strategy",
                    ticker=f"LOAD{i % 5}",  # 5ç¨®é¡ã®ãƒ†ã‚£ãƒƒã‚«ãƒ¼ã‚’å¾ªç’°
                    trigger_type=TriggerType.MANUAL,
                    priority=1,
                    metadata={"load_test": True, "batch": i}
                )
                
                # éåŒæœŸã§åŒæ™‚é€ä¿¡
                task = asyncio.create_task(
                    self.realtime_engine.submit_update_request(request, UpdatePriority.REALTIME)
                )
                concurrent_requests.append(task)
            
            # å…¨ã¦ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Œäº†å¾…æ©Ÿ
            load_task_ids = await asyncio.gather(*concurrent_requests, return_exceptions=True)
            
            load_test_time = time.time() - load_test_start
            successful_load_requests = sum(1 for result in load_task_ids if isinstance(result, str))
            
            results.update({
                "load_test_requests": len(concurrent_requests),
                "successful_load_requests": successful_load_requests,
                "load_test_time": load_test_time,
                "load_test_success_rate": successful_load_requests / len(concurrent_requests)
            })
            
            print(f"   âœ“ Load test: {successful_load_requests}/{len(concurrent_requests)} successful in {load_test_time:.2f}s")
            
            # 4. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
            await asyncio.sleep(3)  # å‡¦ç†å®Œäº†å¾…æ©Ÿ
            
            final_system_status = {
                "trigger_stats": self.trigger_system.get_trigger_statistics(),
                "engine_status": self.realtime_engine.get_engine_status()
            }
            
            results["final_system_status"] = final_system_status
            results["system_still_responsive"] = True
            
            print("   âœ“ System remains responsive after error tests")
            
        except Exception as e:
            results["error"] = str(e)
            results["system_still_responsive"] = False
            logger.error(f"Error handling demo failed: {e}")
        
        self.demo_results["error_handling"] = results
        print("   âœ… Error handling testing completed!")
        print()
    
    async def _display_demo_summary(self):
        """çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º"""
        print("ğŸ“‹ 7. Demo Summary")
        print("=" * 50)
        
        # å®Ÿè¡Œæ™‚é–“
        demo_duration = (datetime.now() - self.demo_start_time).total_seconds()
        print(f"ğŸ“… Total demo time: {demo_duration:.2f} seconds")
        print()
        
        # å„æ®µéšã®çµæœ
        for stage, results in self.demo_results.items():
            print(f"ğŸ” {stage.replace('_', ' ').title()}:")
            
            if isinstance(results, dict):
                if "error" in results:
                    print(f"   âŒ Failed: {results['error']}")
                else:
                    # ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¡¨ç¤º
                    key_metrics = self._extract_key_metrics(stage, results)
                    for metric, value in key_metrics.items():
                        print(f"   âœ“ {metric}: {value}")
            
            print()
        
        # æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        if self.trigger_system and self.realtime_engine:
            print("ğŸ¯ Final System Status:")
            
            trigger_stats = self.trigger_system.get_trigger_statistics()
            engine_status = self.realtime_engine.get_engine_status()
            
            print(f"   ğŸ“Š Total triggers fired: {trigger_stats['total_triggers']}")
            print(f"   âš¡ Total updates processed: {engine_status['total_requests']}")
            print(f"   âœ… Success rate: {(engine_status['successful_updates'] / max(engine_status['total_requests'], 1) * 100):.1f}%")
            print(f"   â±ï¸  Average processing time: {engine_status['average_processing_time']:.4f}s")
            print(f"   ğŸ”„ Queue size: {engine_status['queue_size']}")
            print()
        
        # çµæœä¿å­˜
        demo_summary = {
            "demo_completed_at": datetime.now().isoformat(),
            "demo_duration_seconds": demo_duration,
            "results": self.demo_results
        }
        
        try:
            with open("score_trigger_demo_results.json", "w") as f:
                json.dump(demo_summary, f, indent=2, default=str)
            print("ğŸ’¾ Demo results saved to: score_trigger_demo_results.json")
        except Exception as e:
            logger.warning(f"Failed to save demo results: {e}")
        
        print("âœ… Demo summary completed!")
    
    def _extract_key_metrics(self, stage: str, results: Dict[str, Any]) -> Dict[str, Any]:
        """æ®µéšåˆ¥ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹æŠ½å‡º"""
        key_metrics = {}
        
        if stage == "setup":
            key_metrics["Setup Success"] = results.get("setup_success", False)
        
        elif stage == "basic_triggers":
            key_metrics["Manual Trigger ID"] = results.get("manual_trigger_id", "N/A")
            if "initial_stats" in results:
                stats = results["initial_stats"]
                key_metrics["Initial Triggers"] = stats.get("total_triggers", 0)
        
        elif stage == "threshold_triggers":
            key_metrics["Threshold Events"] = results.get("threshold_events_triggered", 0)
            key_metrics["Initial Scores"] = results.get("initial_scores_generated", 0)
            key_metrics["Change Scores"] = results.get("change_scores_generated", 0)
        
        elif stage == "batch_processing":
            key_metrics["Batch Requests"] = results.get("batch_requests_submitted", 0)
            key_metrics["Processing Time"] = f"{results.get('batch_processing_time', 0):.2f}s"
            key_metrics["Completed"] = results.get("batch_completed", False)
        
        elif stage == "performance_test":
            key_metrics["Throughput"] = f"{results.get('throughput_per_second', 0):.2f} req/s"
            key_metrics["Success Rate"] = f"{results.get('success_rate', 0)*100:.1f}%"
            key_metrics["Avg Processing"] = f"{results.get('average_processing_time', 0):.4f}s"
        
        elif stage == "error_handling":
            key_metrics["Load Test Success"] = f"{results.get('load_test_success_rate', 0)*100:.1f}%"
            key_metrics["System Responsive"] = results.get("system_still_responsive", False)
        
        return key_metrics
    
    async def _cleanup_systems(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("ğŸ§¹ Cleaning up systems...")
        
        try:
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ³ã‚¸ãƒ³åœæ­¢
            if self.realtime_engine:
                await self.realtime_engine.stop()
                print("   âœ“ Realtime engine stopped")
            
            # ãƒˆãƒªã‚¬ãƒ¼ã‚·ã‚¹ãƒ†ãƒ åœæ­¢
            if self.trigger_system:
                self.trigger_system.stop()
                print("   âœ“ Trigger system stopped")
            
        except Exception as e:
            logger.error(f"Cleanup error: {e}")
        
        print("   âœ… Cleanup completed!")


# =============================================================================
# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# =============================================================================

async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    demo = TriggerSystemIntegrationDemo()
    await demo.run_demo()


if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    asyncio.run(main())
