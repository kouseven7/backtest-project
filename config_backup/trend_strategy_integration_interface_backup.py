"""
Module: Trend Strategy Integration Interface
File: trend_strategy_integration_interface.py
Description: 
  3-1-2ã€Œãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šã¨æˆ¦ç•¥ã‚¹ã‚³ã‚¢ã®çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€
  ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šå™¨ã€æˆ¦ç•¥ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€æˆ¦ç•¥é¸æŠå™¨ã®çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®šã¨ãƒãƒƒãƒå‡¦ç†ã«å¯¾å¿œã—ãŸåšã„çµ±åˆãƒ¬ã‚¤ãƒ¤ãƒ¼

Author: imega
Created: 2025-07-13
Modified: 2025-07-13

Dependencies:
  - config.strategy_selector
  - config.strategy_scoring_model
  - indicators.unified_trend_detector
  - config.score_history_manager
"""

import os
import sys
import json
import logging
import asyncio
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Union, Set, Callable
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor, as_completed
import hashlib
import pickle

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã®è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from config.strategy_selector import (
        StrategySelector, SelectionCriteria, StrategySelection, SelectionMethod
    )
    from config.strategy_scoring_model import (
        StrategyScoreCalculator, StrategyScoreManager, StrategyScore
    )
    from indicators.unified_trend_detector import UnifiedTrendDetector
except ImportError as e:
    logging.getLogger(__name__).warning(f"Import error: {e}")

# ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
ScoreHistoryManager = None
TimeDecayFactorCalculator = None

try:
    from config.score_history_manager import ScoreHistoryManager
except ImportError:
    pass

try:
    from config.time_decay_factor import TimeDecayFactorCalculator
except ImportError:
    pass

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logger = logging.getLogger(__name__)

class IntegrationStatus(Enum):
    """çµ±åˆå‡¦ç†ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CACHED = "cached"

class ProcessingMode(Enum):
    """å‡¦ç†ãƒ¢ãƒ¼ãƒ‰"""
    REALTIME = "realtime"          # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
    BATCH = "batch"                # ãƒãƒƒãƒå‡¦ç†
    SCHEDULED = "scheduled"        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«å‡¦ç†
    ON_DEMAND = "on_demand"        # ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰å‡¦ç†

@dataclass
class TrendAnalysisResult:
    """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æçµæœ"""
    trend_type: str
    confidence: float
    strength: float
    reliability: float
    trend_change_probability: float
    supporting_indicators: Dict[str, float]
    analysis_timestamp: datetime
    data_quality_score: float
    trend_duration_estimate: Optional[int] = None
    next_review_time: Optional[datetime] = None

@dataclass
class StrategyScoreBundle:
    """æˆ¦ç•¥ã‚¹ã‚³ã‚¢ãƒãƒ³ãƒ‰ãƒ«"""
    strategy_name: str
    base_score: float
    trend_adjusted_score: float
    confidence_adjusted_score: float
    time_decay_adjusted_score: float
    final_score: float
    score_components: Dict[str, float]
    calculation_metadata: Dict[str, Any]
    last_updated: datetime

@dataclass
class IntegratedDecisionResult:
    """çµ±åˆåˆ¤å®šçµæœ"""
    # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±
    trend_analysis: TrendAnalysisResult
    
    # æˆ¦ç•¥ã‚¹ã‚³ã‚¢æƒ…å ±
    strategy_scores: Dict[str, StrategyScoreBundle]
    
    # æˆ¦ç•¥é¸æŠçµæœ
    strategy_selection: StrategySelection
    
    # çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    processing_mode: ProcessingMode
    integration_status: IntegrationStatus
    processing_time_ms: float
    cache_hit_rate: float
    data_quality_assessment: Dict[str, float]
    
    # ãƒªã‚¹ã‚¯è©•ä¾¡
    risk_assessment: Dict[str, float]
    
    # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    recommended_actions: List[Dict[str, Any]]
    
    # å‡¦ç†è©³ç´°
    ticker: str
    data_period: Tuple[datetime, datetime]
    result_timestamp: datetime = field(default_factory=datetime.now)
    result_id: str = field(default_factory=lambda: hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8])

@dataclass
class BatchProcessingResult:
    """ãƒãƒƒãƒå‡¦ç†çµæœ"""
    total_processed: int
    successful_results: List[IntegratedDecisionResult]
    failed_tickers: List[Tuple[str, str]]  # (ticker, error_message)
    processing_summary: Dict[str, Any]
    batch_start_time: datetime
    batch_end_time: datetime
    batch_id: str = field(default_factory=lambda: hashlib.md5(str(datetime.now()).encode()).hexdigest()[:12])

class TrendStrategyIntegrationInterface:
    """
    ãƒˆãƒ¬ãƒ³ãƒ‰æˆ¦ç•¥çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
    
    æ©Ÿèƒ½:
    1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šâ†’æˆ¦ç•¥ã‚¹ã‚³ã‚¢è¨ˆç®—â†’æˆ¦ç•¥é¸æŠã®çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
    2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¨ãƒãƒƒãƒå‡¦ç†ã®ä¸¡å¯¾å¿œ
    3. é«˜åº¦ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
    4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã¨æœ€é©åŒ–
    """
    
    def __init__(self, 
                 config_file: Optional[str] = None,
                 cache_dir: Optional[str] = None,
                 enable_async: bool = True):
        """çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®åˆæœŸåŒ–"""
        
        self.cache_dir = Path(cache_dir) if cache_dir else Path("cache/integration")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.enable_async = enable_async
        self.config = self._load_config(config_file)
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–
        self._initialize_components()
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
        self._initialize_cache_system()
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
        self._initialize_performance_monitoring()
        
        # éåŒæœŸå‡¦ç†ç”¨
        if enable_async:
            self.executor = ThreadPoolExecutor(max_workers=self.config.get("max_workers", 4))
        
        logger.info("TrendStrategyIntegrationInterface initialized")

    def _load_config(self, config_file: Optional[str]) -> Dict[str, Any]:
        """è¨­å®šã®èª­ã¿è¾¼ã¿"""
        default_config = {
            "cache": {
                "trend_ttl_seconds": 300,       # 5åˆ†
                "score_ttl_seconds": 600,       # 10åˆ†
                "result_ttl_seconds": 180,      # 3åˆ†
                "max_cache_size": 1000
            },
            "processing": {
                "max_workers": 4,
                "batch_size": 50,
                "timeout_seconds": 30,
                "retry_attempts": 3
            },
            "fallback": {
                "default_trend": "sideways",
                "default_confidence": 0.5,
                "fallback_strategies": ["VWAPBounceStrategy", "MomentumInvestingStrategy"]
            },
            "quality": {
                "min_data_points": 20,
                "min_confidence_threshold": 0.3,
                "data_quality_threshold": 0.6
            },
            "trend_strategy_mapping": {
                "uptrend": ["MomentumInvestingStrategy", "BreakoutStrategy", "TrendFollowingStrategy"],
                "downtrend": ["MeanReversionStrategy", "RSIStrategy"],
                "sideways": ["VWAPBounceStrategy", "RSIStrategy", "BollingerBandsStrategy"],
                "unknown": ["VWAPBounceStrategy", "MomentumInvestingStrategy"]
            }
        }
        
        if config_file and Path(config_file).exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # ãƒ‡ã‚£ãƒ¼ãƒ—ãƒãƒ¼ã‚¸
                    self._deep_update(default_config, user_config)
            except Exception as e:
                logger.warning(f"Failed to load config: {e}")
        
        return default_config

    def _deep_update(self, base_dict: Dict[str, Any], update_dict: Dict[str, Any]):
        """è¾æ›¸ã®æ·±ã„ãƒãƒ¼ã‚¸"""
        for key, value in update_dict.items():
            if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                self._deep_update(base_dict[key], value)
            else:
                base_dict[key] = value

    def _initialize_components(self):
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            self.strategy_selector = StrategySelector()
            self.score_calculator = StrategyScoreCalculator()
            self.score_manager = StrategyScoreManager()
            
            # ã‚ªãƒ—ã‚·ãƒ§ãƒŠãƒ«ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
            if ScoreHistoryManager is not None:
                try:
                    self.score_history_manager = ScoreHistoryManager()
                except:
                    self.score_history_manager = None
                    logger.warning("ScoreHistoryManager initialization failed")
            else:
                self.score_history_manager = None
                logger.warning("ScoreHistoryManager not available")
                
            if TimeDecayFactorCalculator is not None:
                try:
                    self.time_decay_calculator = TimeDecayFactorCalculator()
                except:
                    self.time_decay_calculator = None
                    logger.warning("TimeDecayFactorCalculator initialization failed")
            else:
                self.time_decay_calculator = None
                logger.warning("TimeDecayFactorCalculator not available")
            
            logger.info("All components initialized successfully")
        except Exception as e:
            logger.error(f"Component initialization failed: {e}")
            raise

    def _initialize_cache_system(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–"""
        self.trend_cache: Dict[str, Tuple[datetime, TrendAnalysisResult]] = {}
        self.score_cache: Dict[str, Tuple[datetime, StrategyScoreBundle]] = {}
        self.result_cache: Dict[str, Tuple[datetime, IntegratedDecisionResult]] = {}
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0
        }

    def _initialize_performance_monitoring(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ã®åˆæœŸåŒ–"""
        self.performance_metrics: Dict[str, Union[int, float, Dict[str, Any]]] = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_processing_time": 0.0,
            "cache_hit_rate": 0.0,
            "component_performance": {}
        }

    def integrate_decision(self,
                          market_data: pd.DataFrame,
                          ticker: str,
                          selection_criteria: Optional[SelectionCriteria] = None,
                          force_refresh: bool = False) -> IntegratedDecisionResult:
        """çµ±åˆåˆ¤å®šï¼ˆãƒ¡ã‚¤ãƒ³APIï¼‰"""
        start_time = datetime.now()
        
        try:
            # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯
            quality_assessment = self._assess_data_quality(market_data)
            if quality_assessment["overall_quality"] < self.config["quality"]["data_quality_threshold"]:
                logger.warning(f"Low data quality for {ticker}: {quality_assessment}")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
            if not force_refresh:
                cached_result = self._get_cached_result(ticker, market_data)
                if cached_result:
                    self.cache_stats["hits"] += 1
                    cached_result.integration_status = IntegrationStatus.CACHED
                    return cached_result
            
            self.cache_stats["misses"] += 1
            
            # 1. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
            trend_result = self._analyze_trend(market_data, ticker)
            
            # 2. æˆ¦ç•¥ã‚¹ã‚³ã‚¢è¨ˆç®—
            score_bundles = self._calculate_strategy_scores(
                market_data, ticker, trend_result
            )
            
            # 3. æˆ¦ç•¥é¸æŠ
            strategy_selection = self._select_strategies(
                market_data, ticker, trend_result, score_bundles, selection_criteria
            )
            
            # 4. ãƒªã‚¹ã‚¯è©•ä¾¡
            risk_assessment = self._assess_risk(trend_result, strategy_selection, market_data)
            
            # 5. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆ
            recommended_actions = self._generate_recommendations(
                trend_result, strategy_selection, risk_assessment
            )
            
            # 6. çµæœçµ±åˆ
            processing_time = (datetime.now() - start_time).total_seconds() * 1000
            
            integrated_result = IntegratedDecisionResult(
                trend_analysis=trend_result,
                strategy_scores=score_bundles,
                strategy_selection=strategy_selection,
                processing_mode=ProcessingMode.REALTIME,
                integration_status=IntegrationStatus.COMPLETED,
                processing_time_ms=processing_time,
                cache_hit_rate=self._calculate_cache_hit_rate(),
                data_quality_assessment=quality_assessment,
                risk_assessment=risk_assessment,
                recommended_actions=recommended_actions,
                ticker=ticker,
                data_period=(market_data.index[0].to_pydatetime(), market_data.index[-1].to_pydatetime())
            )
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
            self._cache_result(integrated_result)
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ›´æ–°
            self._update_performance_metrics(True, processing_time)
            
            return integrated_result
            
        except Exception as e:
            logger.error(f"Integration failed for {ticker}: {e}")
            self._update_performance_metrics(False, 0)
            return self._create_fallback_result(ticker, market_data, e)

    def _analyze_trend(self, market_data: pd.DataFrame, ticker: str) -> TrendAnalysisResult:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ"""
        try:
            # UnifiedTrendDetectorã‚’ä½¿ç”¨
            trend_detector = UnifiedTrendDetector(
                data=market_data,
                strategy_name="IntegrationInterface",
                method="advanced"
            )
            
            # åŸºæœ¬ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±
            trend = trend_detector.detect_trend()
            confidence = trend_detector.get_confidence()
            strength = trend_detector.get_trend_strength()
            reliability = trend_detector.get_reliability_score()
            
            # è¿½åŠ åˆ†æ
            supporting_indicators = self._calculate_supporting_indicators(market_data)
            trend_change_prob = self._estimate_trend_change_probability(market_data, trend)
            data_quality = self._assess_data_quality_for_trend(market_data)
            
            return TrendAnalysisResult(
                trend_type=trend,
                confidence=confidence,
                strength=strength,
                reliability=reliability,
                trend_change_probability=trend_change_prob,
                supporting_indicators=supporting_indicators,
                analysis_timestamp=datetime.now(),
                data_quality_score=data_quality["overall_quality"],
                trend_duration_estimate=self._estimate_trend_duration(market_data, trend),
                next_review_time=datetime.now() + timedelta(minutes=30)
            )
            
        except Exception as e:
            logger.error(f"Trend analysis failed for {ticker}: {e}")
            return self._create_fallback_trend_analysis()

    def _calculate_strategy_scores(self,
                                 market_data: pd.DataFrame,
                                 ticker: str,
                                 trend_result: TrendAnalysisResult) -> Dict[str, StrategyScoreBundle]:
        """æˆ¦ç•¥ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score_bundles = {}
        
        for strategy_name in self.strategy_selector.available_strategies:
            try:
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
                cache_key = f"score_{strategy_name}_{ticker}_{trend_result.trend_type}"
                cached_score = self._get_cached_score(cache_key)
                if cached_score:
                    score_bundles[strategy_name] = cached_score
                    continue
                
                # ã‚¹ã‚³ã‚¢è¨ˆç®—
                base_score = self.score_calculator.calculate_strategy_score(
                    strategy_name=strategy_name,
                    ticker=ticker,
                    market_data=market_data
                )
                
                if base_score is None:
                    continue
                
                # èª¿æ•´ã‚¹ã‚³ã‚¢ã®è¨ˆç®—
                trend_adjusted = self._apply_trend_adjustment(base_score.total_score, trend_result)
                confidence_adjusted = trend_adjusted * trend_result.confidence
                time_decay_adjusted = self._apply_time_decay(confidence_adjusted, strategy_name)
                final_score = min(1.0, max(0.0, time_decay_adjusted))
                
                score_bundle = StrategyScoreBundle(
                    strategy_name=strategy_name,
                    base_score=base_score.total_score,
                    trend_adjusted_score=trend_adjusted,
                    confidence_adjusted_score=confidence_adjusted,
                    time_decay_adjusted_score=time_decay_adjusted,
                    final_score=final_score,
                    score_components=base_score.component_scores.copy(),
                    calculation_metadata={
                        "trend_type": trend_result.trend_type,
                        "trend_confidence": trend_result.confidence,
                        "data_quality": trend_result.data_quality_score,
                        "calculation_method": "integrated"
                    },
                    last_updated=datetime.now()
                )
                
                score_bundles[strategy_name] = score_bundle
                self._cache_score(cache_key, score_bundle)
                
            except Exception as e:
                logger.warning(f"Score calculation failed for {strategy_name}: {e}")
                continue
        
        return score_bundles

    def _select_strategies(self,
                         market_data: pd.DataFrame,
                         ticker: str,
                         trend_result: TrendAnalysisResult,
                         score_bundles: Dict[str, StrategyScoreBundle],
                         criteria: Optional[SelectionCriteria]) -> StrategySelection:
        """æˆ¦ç•¥é¸æŠ"""
        try:
            # æˆ¦ç•¥é¸æŠå™¨ã‚’ä½¿ç”¨
            selection = self.strategy_selector.select_strategies(
                market_data=market_data,
                ticker=ticker,
                criteria=criteria
            )
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã§æ›´æ–°
            selection.trend_analysis.update({
                "integrated_trend": trend_result.trend_type,
                "integrated_confidence": trend_result.confidence,
                "trend_strength": trend_result.strength,
                "trend_reliability": trend_result.reliability
            })
            
            return selection
            
        except Exception as e:
            logger.error(f"Strategy selection failed for {ticker}: {e}")
            return self._create_fallback_strategy_selection(ticker)

    def _apply_trend_adjustment(self, base_score: float, trend_result: TrendAnalysisResult) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰èª¿æ•´ã®é©ç”¨"""
        try:
            # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ã«ã‚ˆã‚‹èª¿æ•´
            trend_factor = 1.0 + (trend_result.strength - 0.5) * 0.2
            
            # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹èª¿æ•´
            confidence_factor = 0.8 + trend_result.confidence * 0.4
            
            adjusted_score = base_score * trend_factor * confidence_factor
            return min(1.0, max(0.0, adjusted_score))
            
        except Exception as e:
            logger.warning(f"Trend adjustment failed: {e}")
            return base_score

    def _apply_time_decay(self, score: float, strategy_name: str) -> float:
        """æ™‚é–“æ¸›è¡°ã®é©ç”¨"""
        try:
            if self.time_decay_calculator:
                decay_factor = self.time_decay_calculator.calculate_decay_factor(
                    strategy_name=strategy_name,
                    current_time=datetime.now()
                )
                return score * decay_factor
            else:
                return score * 0.95  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè»½å¾®ãªæ¸›è¡°
                
        except Exception as e:
            logger.warning(f"Time decay calculation failed for {strategy_name}: {e}")
            return score * 0.9

    # ============================================================================
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ãƒ»ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ãƒ»ãƒªã‚¹ã‚¯åˆ†æãƒ¡ã‚½ãƒƒãƒ‰
    # ============================================================================

    def _get_cached_result(self, ticker: str, market_data: pd.DataFrame) -> Optional[IntegratedDecisionResult]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸçµ±åˆçµæœã®å–å¾—"""
        cache_key = self._generate_result_cache_key(ticker, market_data)
        
        if cache_key in self.result_cache:
            cached_time, cached_result = self.result_cache[cache_key]
            ttl = self.config["cache"]["result_ttl_seconds"]
            
            if (datetime.now() - cached_time).total_seconds() < ttl:
                logger.debug(f"Cache hit for result: {ticker}")
                return cached_result
            else:
                # æœŸé™åˆ‡ã‚Œã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
                del self.result_cache[cache_key]
                self.cache_stats["evictions"] += 1
        
        return None

    def _cache_result(self, result: IntegratedDecisionResult):
        """çµ±åˆçµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        cache_key = self._generate_result_cache_key(result.ticker, None)
        self.result_cache[cache_key] = (datetime.now(), result)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™
        max_size = self.config["cache"]["max_cache_size"]
        if len(self.result_cache) > max_size:
            self._cleanup_cache("result")

    def _get_cached_score(self, cache_key: str) -> Optional[StrategyScoreBundle]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸã‚¹ã‚³ã‚¢ã®å–å¾—"""
        if cache_key in self.score_cache:
            cached_time, cached_score = self.score_cache[cache_key]
            ttl = self.config["cache"]["score_ttl_seconds"]
            
            if (datetime.now() - cached_time).total_seconds() < ttl:
                return cached_score
            else:
                del self.score_cache[cache_key]
                self.cache_stats["evictions"] += 1
        
        return None

    def _cache_score(self, cache_key: str, score_bundle: StrategyScoreBundle):
        """ã‚¹ã‚³ã‚¢ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥"""
        self.score_cache[cache_key] = (datetime.now(), score_bundle)

    def _generate_result_cache_key(self, ticker: str, market_data: Optional[pd.DataFrame]) -> str:
        """çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã®ç”Ÿæˆ"""
        if market_data is not None:
            # ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒã‚·ãƒ¥ã‚’å«ã‚ã‚‹
            data_hash = hashlib.md5(str(market_data.tail(20).values.tobytes())).hexdigest()[:8]
            return f"result_{ticker}_{data_hash}"
        return f"result_{ticker}"

    def _cleanup_cache(self, cache_type: str):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if cache_type == "result":
            # å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‹ã‚‰å‰Šé™¤
            sorted_entries = sorted(
                self.result_cache.items(),
                key=lambda x: x[1][0]  # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ã‚½ãƒ¼ãƒˆ
            )
            # åŠåˆ†å‰Šé™¤
            for key, _ in sorted_entries[:len(sorted_entries)//2]:
                del self.result_cache[key]
                self.cache_stats["evictions"] += 1

    def _calculate_cache_hit_rate(self) -> float:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®è¨ˆç®—"""
        total = self.cache_stats["hits"] + self.cache_stats["misses"]
        return self.cache_stats["hits"] / total if total > 0 else 0.0

    def _assess_data_quality(self, market_data: pd.DataFrame) -> Dict[str, float]:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªã®è©•ä¾¡"""
        quality_metrics = {}
        
        # 1. ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§
        total_points = len(market_data)
        missing_points = market_data.isnull().sum().sum()
        quality_metrics["completeness"] = 1.0 - (missing_points / (total_points * len(market_data.columns))) if total_points > 0 else 0
        
        # 2. ãƒ‡ãƒ¼ã‚¿é‡ã®å……è¶³æ€§
        min_points = self.config["quality"]["min_data_points"]
        quality_metrics["sufficiency"] = min(1.0, total_points / min_points) if min_points > 0 else 1.0
        
        # 3. ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§
        try:
            prices = market_data['Adj Close']
            price_changes = prices.pct_change().dropna()
            
            # ç•°å¸¸ãªä¾¡æ ¼å¤‰å‹•ã®ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æ¬¡5%ä»¥ä¸Šã®å¤‰å‹•ï¼‰
            extreme_changes = abs(price_changes) > 0.05
            quality_metrics["price_stability"] = 1.0 - (extreme_changes.sum() / len(price_changes)) if len(price_changes) > 0 else 1.0
            
        except:
            quality_metrics["price_stability"] = 0.5
        
        # 4. ç·åˆå“è³ªã‚¹ã‚³ã‚¢
        weights = {
            "completeness": 0.4,
            "sufficiency": 0.3,
            "price_stability": 0.3
        }
        
        overall_quality = sum(
            quality_metrics[metric] * weight 
            for metric, weight in weights.items() 
            if metric in quality_metrics
        )
        
        quality_metrics["overall_quality"] = overall_quality
        
        return quality_metrics

    def _assess_data_quality_for_trend(self, market_data: pd.DataFrame) -> Dict[str, float]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"""
        basic_quality = self._assess_data_quality(market_data)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æç‰¹æœ‰ã®å“è³ªãƒã‚§ãƒƒã‚¯
        try:
            prices = market_data['Adj Close']
            
            # ãƒˆãƒ¬ãƒ³ãƒ‰ã®æ˜ç¢ºæ€§
            returns = prices.pct_change().dropna()
            volatility = returns.std()
            trend_clarity = 1.0 / (1.0 + volatility * 10) if volatility > 0 else 1.0
            
            basic_quality["trend_clarity"] = trend_clarity
            
        except Exception as e:
            logger.warning(f"Trend-specific data quality assessment failed: {e}")
            basic_quality["trend_clarity"] = 0.5
        
        return basic_quality

    def _calculate_supporting_indicators(self, market_data: pd.DataFrame) -> Dict[str, float]:
        """æ”¯æŒæŒ‡æ¨™ã®è¨ˆç®—"""
        indicators = {}
        
        try:
            prices = market_data['Adj Close']
            
            # ç§»å‹•å¹³å‡
            ma_20 = prices.rolling(20).mean()
            ma_50 = prices.rolling(50).mean()
            
            if len(ma_20) > 0 and len(ma_50) > 0:
                current_price = prices.iloc[-1]
                indicators["ma20_position"] = (current_price - ma_20.iloc[-1]) / ma_20.iloc[-1] if ma_20.iloc[-1] != 0 else 0
                indicators["ma50_position"] = (current_price - ma_50.iloc[-1]) / ma_50.iloc[-1] if ma_50.iloc[-1] != 0 else 0
                indicators["ma_cross"] = 1.0 if ma_20.iloc[-1] > ma_50.iloc[-1] else 0.0
            
            # RSIè¿‘ä¼¼
            returns = prices.pct_change().dropna()
            if len(returns) >= 14:
                gains = returns.where(returns > 0, 0)
                losses = -returns.where(returns < 0, 0)
                avg_gain = gains.rolling(14).mean().iloc[-1]
                avg_loss = losses.rolling(14).mean().iloc[-1]
                rs = avg_gain / avg_loss if avg_loss != 0 else 0
                rsi = 100 - (100 / (1 + rs))
                indicators["rsi"] = rsi / 100.0  # 0-1ã‚¹ã‚±ãƒ¼ãƒ«
            
        except Exception as e:
            logger.warning(f"Supporting indicators calculation failed: {e}")
        
        return indicators

    def _estimate_trend_change_probability(self, market_data: pd.DataFrame, current_trend: str) -> float:
        """ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ç¢ºç‡ã®æ¨å®š"""
        try:
            prices = market_data['Adj Close']
            returns = prices.pct_change().dropna()
            
            if len(returns) < 20:
                return 0.5  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ™ãƒ¼ã‚¹ã®å¤‰åŒ–ç¢ºç‡
            recent_vol = returns.tail(10).std()
            historical_vol = returns.std()
            vol_ratio = recent_vol / historical_vol if historical_vol != 0 else 1.0
            
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“ã¯ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ç¢ºç‡ãŒé«˜ã„
            vol_based_prob = min(0.8, vol_ratio * 0.3)
            
            # è¤‡åˆç¢ºç‡
            change_probability = vol_based_prob * 0.7 + 0.2  # åŸºæº–ç¢ºç‡20%
            
            return min(0.9, max(0.1, change_probability))
            
        except Exception as e:
            logger.warning(f"Trend change probability estimation failed: {e}")
            return 0.5

    def _estimate_trend_duration(self, market_data: pd.DataFrame, trend: str) -> Optional[int]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶šæœŸé–“ã®æ¨å®šï¼ˆæ—¥æ•°ï¼‰"""
        try:
            # ç°¡ç•¥åŒ–ã•ã‚ŒãŸå®Ÿè£…
            volatility = market_data['Adj Close'].pct_change().std()
            
            if volatility < 0.01:  # ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                return 30  # 1ãƒ¶æœˆç¨‹åº¦
            elif volatility < 0.02:  # ä¸­ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                return 15  # 2é€±é–“ç¨‹åº¦
            else:  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
                return 7   # 1é€±é–“ç¨‹åº¦
                
        except:
            return None

    def _assess_risk(self, trend_result: TrendAnalysisResult, 
                    strategy_selection: StrategySelection, 
                    market_data: pd.DataFrame) -> Dict[str, float]:
        """åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯è©•ä¾¡"""
        risk_metrics = {}
        
        # 1. ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚¹ã‚¯
        risk_metrics["trend_uncertainty_risk"] = 1.0 - trend_result.confidence
        
        # 2. æˆ¦ç•¥é›†ä¸­åº¦ãƒªã‚¹ã‚¯
        weights = list(strategy_selection.strategy_weights.values())
        if weights:
            # ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«æŒ‡æ•°ï¼ˆé›†ä¸­åº¦æŒ‡æ¨™ï¼‰
            hhi = sum(w**2 for w in weights)
            n_strategies = len(weights)
            min_hhi = 1.0 / n_strategies if n_strategies > 0 else 1.0
            
            if hhi <= min_hhi:
                risk_metrics["concentration_risk"] = 0.0
            else:
                risk_metrics["concentration_risk"] = (hhi - min_hhi) / (1.0 - min_hhi)
        else:
            risk_metrics["concentration_risk"] = 1.0
        
        # 3. å¸‚å ´ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯
        try:
            returns = market_data['Adj Close'].pct_change().dropna()
            if len(returns) >= 10:
                current_vol = returns.std()
                annual_vol = current_vol * np.sqrt(252)
                
                # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’0-1ã‚¹ã‚±ãƒ¼ãƒ«ã«ãƒãƒƒãƒ”ãƒ³ã‚°
                if annual_vol < 0.2:
                    risk_metrics["volatility_risk"] = annual_vol / 0.2 * 0.3  # 0-0.3
                elif annual_vol < 0.4:
                    risk_metrics["volatility_risk"] = 0.3 + (annual_vol - 0.2) / 0.2 * 0.4  # 0.3-0.7
                else:
                    risk_metrics["volatility_risk"] = min(1.0, 0.7 + (annual_vol - 0.4) / 0.6 * 0.3)  # 0.7-1.0
            else:
                risk_metrics["volatility_risk"] = 0.5
        except:
            risk_metrics["volatility_risk"] = 0.5
        
        # 4. ç·åˆãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢
        risk_metrics["overall_risk"] = (
            risk_metrics["trend_uncertainty_risk"] * 0.4 +
            risk_metrics["concentration_risk"] * 0.3 +
            risk_metrics["volatility_risk"] * 0.3
        )
        
        return risk_metrics

    def _generate_recommendations(self, trend_result: TrendAnalysisResult,
                                strategy_selection: StrategySelection,
                                risk_assessment: Dict[str, float]) -> List[Dict[str, Any]]:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ç”Ÿæˆ"""
        recommendations = []
        
        # 1. é«˜ãƒªã‚¹ã‚¯è­¦å‘Š
        if risk_assessment["overall_risk"] > 0.7:
            recommendations.append({
                "type": "risk_warning",
                "priority": "high",
                "title": "é«˜ãƒªã‚¹ã‚¯è­¦å‘Š",
                "description": f"ç·åˆãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ {risk_assessment['overall_risk']:.2f} - æ…é‡ãªå–å¼•ã‚’æ¨å¥¨",
                "action_items": [
                    "ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã®ç¸®å°ã‚’æ¤œè¨",
                    "è¿½åŠ çš„ãªãƒªã‚¹ã‚¯ç®¡ç†æ‰‹æ³•ã®é©ç”¨",
                    "é »ç¹ãªç›£è¦–ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼"
                ]
            })
        
        # 2. ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡é ¼åº¦ã«åŸºã¥ãæ¨å¥¨
        if trend_result.confidence < 0.6:
            recommendations.append({
                "type": "trend_confidence",
                "priority": "medium",
                "title": "ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡é ¼åº¦ä½ä¸‹",
                "description": f"ãƒˆãƒ¬ãƒ³ãƒ‰ä¿¡é ¼åº¦ {trend_result.confidence:.2f} - è¿½åŠ åˆ†æãŒå¿…è¦",
                "action_items": [
                    "ã‚ˆã‚Šé•·æœŸãƒ‡ãƒ¼ã‚¿ã§ã®å†åˆ†æ",
                    "è¤‡æ•°ã®æ™‚é–“è»¸ã§ã®ç¢ºèª",
                    "ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™ã®ç¢ºèª"
                ]
            })
        
        # 3. æˆ¦ç•¥é›†ä¸­åº¦è­¦å‘Š
        if risk_assessment.get("concentration_risk", 0) > 0.6:
            recommendations.append({
                "type": "diversification",
                "priority": "medium",
                "title": "æˆ¦ç•¥åˆ†æ•£åŒ–æ¨å¥¨",
                "description": "æˆ¦ç•¥ãŒé›†ä¸­ã—ã¦ã„ã¾ã™ - åˆ†æ•£åŒ–ã‚’æ¤œè¨",
                "action_items": [
                    "è¿½åŠ æˆ¦ç•¥ã®é¸æŠã‚’æ¤œè¨",
                    "æˆ¦ç•¥é‡ã¿ã®å†èª¿æ•´",
                    "ç•°ãªã‚‹ç‰¹æ€§ã®æˆ¦ç•¥ã‚’è¿½åŠ "
                ]
            })
        
        # 4. å®šæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼æ¨å¥¨
        recommendations.append({
            "type": "review_schedule",
            "priority": "info",
            "title": "å®šæœŸãƒ¬ãƒ“ãƒ¥ãƒ¼",
            "description": "æˆ¦ç•¥é¸æŠã®å®šæœŸçš„ãªè¦‹ç›´ã—ã‚’æ¨å¥¨",
            "action_items": [
                f"æ¬¡å›ãƒ¬ãƒ“ãƒ¥ãƒ¼: {trend_result.next_review_time.strftime('%Y-%m-%d %H:%M') if trend_result.next_review_time else '24æ™‚é–“å¾Œ'}",
                "å¸‚å ´ç’°å¢ƒå¤‰åŒ–ã®ç›£è¦–",
                "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡"
            ]
        })
        
        return recommendations

    # ============================================================================
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
    # ============================================================================

    def _create_fallback_result(self, ticker: str, market_data: pd.DataFrame, error: Exception) -> IntegratedDecisionResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯çµ±åˆçµæœã®ä½œæˆ"""
        logger.warning(f"Creating fallback result for {ticker}: {error}")
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        fallback_trend = self._create_fallback_trend_analysis()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨æˆ¦ç•¥é¸æŠ
        fallback_strategies = self.config["fallback"]["fallback_strategies"]
        fallback_selection = self._create_fallback_strategy_selection(ticker, fallback_strategies)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã‚¹ã‚³ã‚¢ãƒãƒ³ãƒ‰ãƒ«
        fallback_score_bundles = {}
        for strategy in fallback_strategies:
            fallback_score_bundles[strategy] = StrategyScoreBundle(
                strategy_name=strategy,
                base_score=0.5,
                trend_adjusted_score=0.5,
                confidence_adjusted_score=0.4,
                time_decay_adjusted_score=0.4,
                final_score=0.4,
                score_components={"fallback": 0.4},
                calculation_metadata={"fallback": True, "error": str(error)},
                last_updated=datetime.now()
            )
        
        return IntegratedDecisionResult(
            trend_analysis=fallback_trend,
            strategy_scores=fallback_score_bundles,
            strategy_selection=fallback_selection,
            processing_mode=ProcessingMode.ON_DEMAND,
            integration_status=IntegrationStatus.FAILED,
            processing_time_ms=0.0,
            cache_hit_rate=0.0,
            data_quality_assessment={"overall_quality": 0.3},
            risk_assessment={"overall_risk": 0.8, "fallback_risk": 1.0},
            recommended_actions=[{
                "type": "system_error",
                "priority": "high",
                "title": "ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†",
                "description": f"çµ±åˆå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(error)[:100]}",
                "action_items": [
                    "ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã®ç¢ºèª",
                    "ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª", 
                    "æ‰‹å‹•ã§ã®æˆ¦ç•¥é¸æŠã‚’æ¤œè¨"
                ]
            }],
            ticker=ticker,
            data_period=(datetime.now() - timedelta(days=30), datetime.now()),
            result_timestamp=datetime.now()
        )

    def _create_fallback_trend_analysis(self) -> TrendAnalysisResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®ä½œæˆ"""
        return TrendAnalysisResult(
            trend_type=self.config["fallback"]["default_trend"],
            confidence=self.config["fallback"]["default_confidence"],
            strength=0.5,
            reliability=0.5,
            trend_change_probability=0.5,
            supporting_indicators={},
            analysis_timestamp=datetime.now(),
            data_quality_score=0.5
        )

    def _create_fallback_strategy_selection(self, ticker: str, strategies: Optional[List[str]] = None) -> StrategySelection:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥é¸æŠã®ä½œæˆ"""
        if strategies is None:
            strategies = self.config["fallback"]["fallback_strategies"]
        
        if not strategies:
            strategies = ["conservative"]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæˆ¦ç•¥
        
        equal_weight = 1.0 / len(strategies) if strategies else 0.0
        
        return StrategySelection(
            selected_strategies=strategies,
            strategy_scores={s: 0.5 for s in strategies},
            strategy_weights={s: equal_weight for s in strategies},
            selection_reason="Fallback selection due to system error",
            trend_analysis={"trend": "unknown", "confidence": 0.5},
            confidence_level=0.5,
            total_score=0.5,
            metadata={"fallback": True, "ticker": ticker}
        )

    def _update_performance_metrics(self, success: bool, processing_time: float):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®æ›´æ–°"""
        self.performance_metrics["total_requests"] += 1  # type: ignore
        
        if success:
            self.performance_metrics["successful_requests"] += 1  # type: ignore
        else:
            self.performance_metrics["failed_requests"] += 1  # type: ignore
        
        # å¹³å‡å‡¦ç†æ™‚é–“ã®æ›´æ–°
        current_avg = self.performance_metrics["average_processing_time"]  # type: ignore
        total_requests = self.performance_metrics["total_requests"]  # type: ignore
        new_avg = (current_avg * (total_requests - 1) + processing_time) / total_requests  # type: ignore
        self.performance_metrics["average_processing_time"] = new_avg
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®æ›´æ–°
        self.performance_metrics["cache_hit_rate"] = self._calculate_cache_hit_rate()

    # ============================================================================
    # å…¬é–‹APIãƒ»ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    # ============================================================================

    def get_performance_statistics(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆã®å–å¾—"""
        return {
            "performance_metrics": self.performance_metrics.copy(),
            "cache_statistics": self.cache_stats.copy(),
            "cache_sizes": {
                "result_cache": len(self.result_cache),
                "score_cache": len(self.score_cache),
                "trend_cache": len(self.trend_cache)
            }
        }

    def validate_market_data(self, market_data: pd.DataFrame) -> Tuple[bool, List[str]]:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼"""
        issues: List[str] = []
        
        # å¿…é ˆã‚«ãƒ©ãƒ ã®ãƒã‚§ãƒƒã‚¯
        required_columns = ['Adj Close']
        for col in required_columns:
            if col not in market_data.columns:
                issues.append(f"Missing required column: {col}")
        
        # ãƒ‡ãƒ¼ã‚¿é‡ã®ãƒã‚§ãƒƒã‚¯
        min_points = self.config["quality"]["min_data_points"]
        if len(market_data) < min_points:
            issues.append(f"Insufficient data points: {len(market_data)} < {min_points}")
        
        return len(issues) == 0, issues

    def cleanup_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        self._cleanup_cache("result")
        logger.info("System cleanup completed")


# ============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼é–¢æ•°ãƒ»ä¾¿åˆ©é–¢æ•°
# ============================================================================

def create_integration_interface(config_file: Optional[str] = None,
                                cache_dir: Optional[str] = None,
                                enable_async: bool = True) -> TrendStrategyIntegrationInterface:
    """çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ"""
    return TrendStrategyIntegrationInterface(
        config_file=config_file,
        cache_dir=cache_dir,
        enable_async=enable_async
    )

def quick_strategy_decision(market_data: pd.DataFrame,
                           ticker: str,
                           max_strategies: int = 3) -> IntegratedDecisionResult:
    """ã‚¯ã‚¤ãƒƒã‚¯æˆ¦ç•¥åˆ¤å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    interface = create_integration_interface(enable_async=False)
    
    criteria = SelectionCriteria(
        method=SelectionMethod.HYBRID,
        max_strategies=max_strategies,
        min_score_threshold=0.5
    )
    
    return interface.integrate_decision(market_data, ticker, criteria)


# ä¸€æ™‚çš„ãªå‹å®šç¾©ï¼ˆå®Ÿéš›ã®å®Ÿè£…ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
if StrategySelection is None:
    @dataclass
    class StrategySelection:  # type: ignore
        selected_strategies: List[str] = field(default_factory=list)
        strategy_scores: Dict[str, float] = field(default_factory=dict)
        strategy_weights: Dict[str, float] = field(default_factory=dict)
        selection_reason: str = ""
        trend_analysis: Dict[str, Any] = field(default_factory=dict)
        confidence_level: float = 0.0
        total_score: float = 0.0
        metadata: Dict[str, Any] = field(default_factory=dict)

if SelectionCriteria is None:
    @dataclass
    class SelectionCriteria:  # type: ignore
        method: str = "hybrid"
        max_strategies: int = 3
        min_score_threshold: float = 0.5

if SelectionMethod is None:
    class SelectionMethod:  # type: ignore
        HYBRID = "hybrid"
        TOP_SCORE = "top_score"
        WEIGHT_BASED = "weight_based"


# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
__all__ = [
    "TrendStrategyIntegrationInterface",
    "IntegratedDecisionResult",
    "TrendAnalysisResult",
    "StrategyScoreBundle",
    "BatchProcessingResult",
    "IntegrationStatus",
    "ProcessingMode",
    "create_integration_interface",
    "quick_strategy_decision"
]


if __name__ == "__main__":
    # ç°¡å˜ãªãƒ†ã‚¹ãƒˆ
    import pandas as pd
    import numpy as np
    
    print("ğŸ”§ TrendStrategyIntegrationInterface ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dates = pd.date_range('2023-01-01', periods=100, freq='D')
    sample_data = pd.DataFrame({
        'Adj Close': 100 + np.random.randn(100).cumsum(),
        'Volume': np.random.randint(1000, 10000, 100)
    }, index=dates)
    
    # çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ
    print("ğŸ“Š çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ...")
    try:
        interface = create_integration_interface(enable_async=False)
        print("  âœ“ åˆæœŸåŒ–æˆåŠŸ")
        
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ã‚¹ãƒˆ
        is_valid, issues = interface.validate_market_data(sample_data)
        print(f"  ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼: {'âœ“ æœ‰åŠ¹' if is_valid else 'âŒ ç„¡åŠ¹'}")
        if issues:
            for issue in issues:
                print(f"    - {issue}")
        
        # ã‚·ãƒ³ã‚°ãƒ«åˆ¤å®šãƒ†ã‚¹ãƒˆ
        print("ğŸ“Š ã‚·ãƒ³ã‚°ãƒ«åˆ¤å®šãƒ†ã‚¹ãƒˆ...")
        result = interface.integrate_decision(sample_data, "TEST")
        print(f"  é¸æŠæˆ¦ç•¥: {result.strategy_selection.selected_strategies}")
        print(f"  ãƒˆãƒ¬ãƒ³ãƒ‰: {result.trend_analysis.trend_type} (ä¿¡é ¼åº¦: {result.trend_analysis.confidence:.2f})")
        print(f"  ç·åˆãƒªã‚¹ã‚¯: {result.risk_assessment.get('overall_risk', 'N/A')}")
        print(f"  å‡¦ç†æ™‚é–“: {result.processing_time_ms:.1f}ms")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        stats = interface.get_performance_statistics()
        print(f"  æˆåŠŸç‡: {stats['performance_metrics']['successful_requests']}/{stats['performance_metrics']['total_requests']}")
        
        print("âœ… 3-1-2ã€Œãƒˆãƒ¬ãƒ³ãƒ‰æˆ¦ç•¥çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã€å®Ÿè£…å®Œäº†ï¼")
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
