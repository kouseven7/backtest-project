"""
Module: Strategy Dependency Resolver
File: strategy_dependency_resolver.py
Description: 
  4-1-3ã€Œãƒãƒ«ãƒæˆ¦ç•¥åŒæ™‚å®Ÿè¡Œã®èª¿æ•´æ©Ÿèƒ½ã€
  æˆ¦ç•¥ä¾å­˜é–¢ä¿‚è§£æ±ºãƒ»å®Ÿè¡Œé †åºæœ€é©åŒ–

Author: imega
Created: 2025-07-20
Modified: 2025-07-20

Functions:
  - ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•æ§‹ç¯‰ãƒ»å¾ªç’°å‚ç…§æ¤œå‡º
  - å®Ÿè¡Œé †åºæœ€é©åŒ–ãƒ»ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½æ€§åˆ†æ
  - ãƒ‡ãƒ¼ã‚¿å…±æœ‰æœ€é©åŒ–ãƒ»ä¾å­˜é–¢ä¿‚ç®¡ç†
  - å‹•çš„ä¾å­˜é–¢ä¿‚è§£æ±ºãƒ»å®Ÿè¡Œæ™‚èª¿æ•´
"""

import os
import sys
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Set, Tuple, Union
from enum import Enum
from dataclasses import dataclass, asdict, field
from collections import defaultdict, deque
import threading
from concurrent.futures import Future
import networkx as nx
import hashlib

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

class DependencyType(Enum):
    """ä¾å­˜é–¢ä¿‚ç¨®åˆ¥"""
    DATA = "data"
    TEMPORAL = "temporal"
    RESOURCE = "resource"
    LOGICAL = "logical"

class ExecutionPhase(Enum):
    """å®Ÿè¡Œãƒ•ã‚§ãƒ¼ã‚º"""
    PREPARATION = "preparation"
    ANALYSIS = "analysis" 
    EXECUTION = "execution"
    POST_PROCESSING = "post_processing"

class DependencyStatus(Enum):
    """ä¾å­˜é–¢ä¿‚çŠ¶æ…‹"""
    PENDING = "pending"
    SATISFIED = "satisfied"
    FAILED = "failed"
    EXPIRED = "expired"

@dataclass
class StrategyDependency:
    """æˆ¦ç•¥ä¾å­˜é–¢ä¿‚"""
    source_strategy: str
    target_strategy: str
    dependency_type: DependencyType
    data_key: Optional[str] = None
    is_critical: bool = True
    timeout_seconds: float = 300.0
    retry_count: int = 3
    description: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['dependency_type'] = self.dependency_type.value
        return result
    
    def get_dependency_id(self) -> str:
        """ä¾å­˜é–¢ä¿‚IDç”Ÿæˆ"""
        content = f"{self.source_strategy}->{self.target_strategy}:{self.dependency_type.value}:{self.data_key or 'none'}"
        return hashlib.md5(content.encode()).hexdigest()[:16]

@dataclass
class ExecutionNode:
    """å®Ÿè¡Œãƒãƒ¼ãƒ‰"""
    strategy_name: str
    phase: ExecutionPhase
    dependencies: List[StrategyDependency] = field(default_factory=list)
    execution_priority: int = 1
    estimated_duration: float = 30.0
    resource_requirements: Dict[str, Any] = field(default_factory=dict)
    parallel_capable: bool = True
    data_outputs: List[str] = field(default_factory=list)
    data_inputs: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['phase'] = self.phase.value
        result['dependencies'] = [dep.to_dict() for dep in self.dependencies]
        return result
    
    def get_node_id(self) -> str:
        """ãƒãƒ¼ãƒ‰IDç”Ÿæˆ"""
        return f"{self.strategy_name}#{self.phase.value}"

@dataclass
class ExecutionGraph:
    """å®Ÿè¡Œã‚°ãƒ©ãƒ•"""
    nodes: List[ExecutionNode] = field(default_factory=list)
    edges: List[StrategyDependency] = field(default_factory=list)
    execution_levels: List[List[str]] = field(default_factory=list)
    shared_data_keys: Set[str] = field(default_factory=set)
    
    def to_dict(self) -> Dict[str, Any]:
        result = {
            'nodes': [node.to_dict() for node in self.nodes],
            'edges': [edge.to_dict() for edge in self.edges],
            'execution_levels': self.execution_levels,
            'shared_data_keys': list(self.shared_data_keys)
        }
        return result

@dataclass
class DependencyResolution:
    """ä¾å­˜é–¢ä¿‚è§£æ±ºçµæœ"""
    resolved_dependencies: List[StrategyDependency]
    execution_order: List[str]
    parallel_groups: List[List[str]]
    data_flow_optimization: Dict[str, Any]
    critical_path_duration: float
    optimization_suggestions: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['resolved_dependencies'] = [dep.to_dict() for dep in self.resolved_dependencies]
        return result

class DataFlowTracker:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è¿½è·¡å™¨"""
    
    def __init__(self):
        self.data_registry: Dict[str, Any] = {}
        self.data_dependencies: Dict[str, Set[str]] = defaultdict(set)
        self.data_consumers: Dict[str, Set[str]] = defaultdict(set)
        self.access_lock = threading.Lock()
        
    def register_data_output(self, strategy_name: str, data_key: str, data_value: Any = None):
        """ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ç™»éŒ²"""
        with self.access_lock:
            self.data_registry[data_key] = {
                'value': data_value,
                'producer': strategy_name,
                'timestamp': datetime.now(),
                'access_count': 0
            }
            logger.debug(f"Registered data output: {data_key} from {strategy_name}")
    
    def register_data_input(self, strategy_name: str, data_key: str):
        """ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ç™»éŒ²"""
        with self.access_lock:
            self.data_dependencies[strategy_name].add(data_key)
            self.data_consumers[data_key].add(strategy_name)
            logger.debug(f"Registered data input: {data_key} for {strategy_name}")
    
    def check_data_availability(self, data_keys: List[str]) -> Dict[str, bool]:
        """ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨å¯èƒ½æ€§ç¢ºèª"""
        with self.access_lock:
            return {
                key: key in self.data_registry 
                for key in data_keys
            }
    
    def get_data(self, data_key: str) -> Optional[Any]:
        """ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        with self.access_lock:
            if data_key in self.data_registry:
                self.data_registry[data_key]['access_count'] += 1
                return self.data_registry[data_key]['value']
            return None
    
    def get_data_flow_stats(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼çµ±è¨ˆ"""
        with self.access_lock:
            return {
                'total_data_keys': len(self.data_registry),
                'dependency_count': sum(len(deps) for deps in self.data_dependencies.values()),
                'consumer_count': sum(len(consumers) for consumers in self.data_consumers.values()),
                'data_utilization': {
                    key: info['access_count'] 
                    for key, info in self.data_registry.items()
                }
            }

class StrategyDependencyResolver:
    """æˆ¦ç•¥ä¾å­˜é–¢ä¿‚ãƒªã‚¾ãƒ«ãƒãƒ¼"""
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.data_flow_tracker = DataFlowTracker()
        self.dependency_graph = nx.DiGraph()
        self.execution_history: List[Dict[str, Any]] = []
        self.dependency_cache: Dict[str, ExecutionGraph] = {}
        
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), 'coordination_config.json')
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load config from {config_path}: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            "dependency_management": {
                "max_dependency_depth": 10,
                "parallel_execution_threshold": 2,
                "data_sharing_optimization": True,
                "dependency_timeout": 300,
                "cache_dependency_resolution": True
            },
            "strategy_profiles": {},
            "execution_phases": {
                "preparation": {"weight": 0.1, "parallel_factor": 0.8},
                "analysis": {"weight": 0.3, "parallel_factor": 0.6},
                "execution": {"weight": 0.5, "parallel_factor": 0.4},
                "post_processing": {"weight": 0.1, "parallel_factor": 0.9}
            }
        }
    
    def build_dependency_graph(self, strategies: List[str]) -> ExecutionGraph:
        """ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•æ§‹ç¯‰"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = self._generate_cache_key(strategies)
        if (self.config.get('dependency_management', {}).get('cache_dependency_resolution', True) and
            cache_key in self.dependency_cache):
            logger.info(f"Using cached dependency graph for {len(strategies)} strategies")
            return self.dependency_cache[cache_key]
        
        logger.info(f"Building dependency graph for strategies: {strategies}")
        
        # ãƒãƒ¼ãƒ‰ä½œæˆ
        nodes = []
        edges = []
        
        for strategy in strategies:
            strategy_profile = self.config.get('strategy_profiles', {}).get(strategy, {})
            
            # å„ãƒ•ã‚§ãƒ¼ã‚ºã®ãƒãƒ¼ãƒ‰ä½œæˆ
            for phase in ExecutionPhase:
                node = ExecutionNode(
                    strategy_name=strategy,
                    phase=phase,
                    execution_priority=strategy_profile.get('priority', 1),
                    estimated_duration=strategy_profile.get('expected_duration', 30.0) * 
                                     self.config.get('execution_phases', {}).get(phase.value, {}).get('weight', 0.25),
                    resource_requirements=strategy_profile.get('resource_requirements', {}),
                    parallel_capable=strategy_profile.get('parallel_capable', True),
                    data_outputs=strategy_profile.get('data_outputs', []),
                    data_inputs=strategy_profile.get('data_inputs', [])
                )
                nodes.append(node)
        
        # ä¾å­˜é–¢ä¿‚æ§‹ç¯‰
        edges = self._build_strategy_dependencies(strategies, nodes)
        
        # NetworkXã‚°ãƒ©ãƒ•æ§‹ç¯‰
        self.dependency_graph.clear()
        for node in nodes:
            self.dependency_graph.add_node(node.get_node_id(), **node.to_dict())
        
        for edge in edges:
            source_id = f"{edge.source_strategy}#{ExecutionPhase.EXECUTION.value}"
            target_id = f"{edge.target_strategy}#{ExecutionPhase.PREPARATION.value}"
            self.dependency_graph.add_edge(source_id, target_id, **edge.to_dict())
        
        # å¾ªç’°å‚ç…§æ¤œå‡º
        if not nx.is_directed_acyclic_graph(self.dependency_graph):
            cycles = list(nx.simple_cycles(self.dependency_graph))
            logger.error(f"Circular dependencies detected: {cycles}")
            raise ValueError(f"Circular dependencies found: {cycles}")
        
        # å®Ÿè¡Œãƒ¬ãƒ™ãƒ«è¨ˆç®—
        execution_levels = self._calculate_execution_levels()
        
        # å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼æŠ½å‡º
        shared_data_keys = set()
        for node in nodes:
            shared_data_keys.update(node.data_outputs)
            shared_data_keys.update(node.data_inputs)
        
        execution_graph = ExecutionGraph(
            nodes=nodes,
            edges=edges,
            execution_levels=execution_levels,
            shared_data_keys=shared_data_keys
        )
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        if self.config.get('dependency_management', {}).get('cache_dependency_resolution', True):
            self.dependency_cache[cache_key] = execution_graph
        
        logger.info(f"Built dependency graph with {len(nodes)} nodes, {len(edges)} edges, {len(execution_levels)} levels")
        
        return execution_graph
    
    def _generate_cache_key(self, strategies: List[str]) -> str:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ç”Ÿæˆ"""
        content = "|".join(sorted(strategies))
        return hashlib.md5(content.encode()).hexdigest()
    
    def _build_strategy_dependencies(self, strategies: List[str], nodes: List[ExecutionNode]) -> List[StrategyDependency]:
        """æˆ¦ç•¥ä¾å­˜é–¢ä¿‚æ§‹ç¯‰"""
        dependencies = []
        
        # ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ä¾å­˜é–¢ä¿‚
        for strategy in strategies:
            strategy_profile = self.config.get('strategy_profiles', {}).get(strategy, {})
            strategy_deps = strategy_profile.get('dependencies', [])
            
            for dep_config in strategy_deps:
                if isinstance(dep_config, str):
                    # ã‚·ãƒ³ãƒ—ãƒ«ä¾å­˜é–¢ä¿‚
                    target_strategy = dep_config
                    if target_strategy in strategies:
                        dependency = StrategyDependency(
                            source_strategy=target_strategy,
                            target_strategy=strategy,
                            dependency_type=DependencyType.LOGICAL,
                            description=f"{strategy} depends on {target_strategy}"
                        )
                        dependencies.append(dependency)
                
                elif isinstance(dep_config, dict):
                    # è©³ç´°ä¾å­˜é–¢ä¿‚è¨­å®š
                    target_strategy = dep_config.get('strategy')
                    if target_strategy and target_strategy in strategies:
                        dependency = StrategyDependency(
                            source_strategy=target_strategy,
                            target_strategy=strategy,
                            dependency_type=DependencyType(dep_config.get('type', 'logical')),
                            data_key=dep_config.get('data_key'),
                            is_critical=dep_config.get('critical', True),
                            timeout_seconds=dep_config.get('timeout', 300.0),
                            description=dep_config.get('description', '')
                        )
                        dependencies.append(dependency)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¾å­˜é–¢ä¿‚
        data_dependencies = self._analyze_data_flow_dependencies(nodes)
        dependencies.extend(data_dependencies)
        
        return dependencies
    
    def _analyze_data_flow_dependencies(self, nodes: List[ExecutionNode]) -> List[StrategyDependency]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¾å­˜é–¢ä¿‚åˆ†æ"""
        dependencies = []
        
        # ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›â†’å…¥åŠ›ãƒãƒƒãƒ”ãƒ³ã‚°
        data_producers = {}
        data_consumers = defaultdict(list)
        
        for node in nodes:
            # ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›è€…è¨˜éŒ²
            for data_key in node.data_outputs:
                data_producers[data_key] = node.strategy_name
            
            # ãƒ‡ãƒ¼ã‚¿æ¶ˆè²»è€…è¨˜éŒ²
            for data_key in node.data_inputs:
                data_consumers[data_key].append(node.strategy_name)
        
        # ä¾å­˜é–¢ä¿‚æ§‹ç¯‰
        for data_key, consumers in data_consumers.items():
            if data_key in data_producers:
                producer = data_producers[data_key]
                for consumer in consumers:
                    if producer != consumer:  # è‡ªå·±å‚ç…§ã¯é™¤å¤–
                        dependency = StrategyDependency(
                            source_strategy=producer,
                            target_strategy=consumer,
                            dependency_type=DependencyType.DATA,
                            data_key=data_key,
                            description=f"{consumer} needs data '{data_key}' from {producer}"
                        )
                        dependencies.append(dependency)
        
        return dependencies
    
    def _calculate_execution_levels(self) -> List[List[str]]:
        """å®Ÿè¡Œãƒ¬ãƒ™ãƒ«è¨ˆç®—ï¼ˆãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆï¼‰"""
        if not self.dependency_graph.nodes():
            return []
        
        levels = []
        graph_copy = self.dependency_graph.copy()
        
        while graph_copy.nodes():
            # å…¥åŠ›ã‚¨ãƒƒã‚¸ãŒãªã„ãƒãƒ¼ãƒ‰ã‚’è¦‹ã¤ã‘ã‚‹
            current_level = [
                node for node in graph_copy.nodes()
                if graph_copy.in_degree(node) == 0
            ]
            
            if not current_level:
                # ã™ã¹ã¦ã®ãƒãƒ¼ãƒ‰ã«å…¥åŠ›ã‚¨ãƒƒã‚¸ãŒã‚ã‚‹ = å¾ªç’°å‚ç…§
                remaining = list(graph_copy.nodes())
                logger.error(f"Cannot resolve dependencies, remaining nodes: {remaining}")
                break
            
            levels.append(current_level)
            graph_copy.remove_nodes_from(current_level)
        
        return levels
    
    def resolve_dependencies(self, strategies: List[str]) -> DependencyResolution:
        """ä¾å­˜é–¢ä¿‚è§£æ±º"""
        logger.info(f"Resolving dependencies for {len(strategies)} strategies")
        
        # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•æ§‹ç¯‰
        execution_graph = self.build_dependency_graph(strategies)
        
        # å®Ÿè¡Œé †åºè¨ˆç®—
        execution_order = []
        for level in execution_graph.execution_levels:
            # ãƒ¬ãƒ™ãƒ«å†…ã§ã®å„ªå…ˆåº¦ã‚½ãƒ¼ãƒˆ
            level_strategies = []
            for node_id in level:
                strategy_name = node_id.split('#')[0]
                if strategy_name not in level_strategies:
                    level_strategies.append(strategy_name)
            
            # å„ªå…ˆåº¦ã¨ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚é‡ã«ã‚ˆã‚‹ã‚½ãƒ¼ãƒˆ
            level_strategies.sort(key=lambda s: (
                -self.config.get('strategy_profiles', {}).get(s, {}).get('priority', 1),
                -self.config.get('strategy_profiles', {}).get(s, {}).get('expected_duration', 30.0)
            ))
            
            execution_order.extend(level_strategies)
        
        # ä¸¦åˆ—ã‚°ãƒ«ãƒ¼ãƒ—è¨ˆç®—
        parallel_groups = self._calculate_parallel_groups(execution_graph)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–
        data_flow_optimization = self._optimize_data_flow(execution_graph)
        
        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹è¨ˆç®—
        critical_path_duration = self._calculate_critical_path_duration(execution_graph)
        
        # æœ€é©åŒ–ææ¡ˆç”Ÿæˆ
        optimization_suggestions = self._generate_optimization_suggestions(
            execution_graph, critical_path_duration
        )
        
        resolution = DependencyResolution(
            resolved_dependencies=execution_graph.edges,
            execution_order=execution_order,
            parallel_groups=parallel_groups,
            data_flow_optimization=data_flow_optimization,
            critical_path_duration=critical_path_duration,
            optimization_suggestions=optimization_suggestions
        )
        
        # å±¥æ­´ä¿å­˜
        self.execution_history.append({
            'timestamp': datetime.now().isoformat(),
            'strategies': strategies,
            'resolution': resolution.to_dict()
        })
        
        logger.info(f"Dependency resolution complete: {len(execution_order)} strategies, {len(parallel_groups)} parallel groups")
        
        return resolution
    
    def _calculate_parallel_groups(self, execution_graph: ExecutionGraph) -> List[List[str]]:
        """ä¸¦åˆ—å®Ÿè¡Œã‚°ãƒ«ãƒ¼ãƒ—è¨ˆç®—"""
        parallel_groups = []
        
        for level in execution_graph.execution_levels:
            level_strategies = set()
            for node_id in level:
                strategy_name = node_id.split('#')[0]
                level_strategies.add(strategy_name)
            
            # ãƒ¬ãƒ™ãƒ«å†…ã§ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½ãªã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
            if len(level_strategies) > 1:
                # ä¸¦åˆ—å®Ÿè¡Œå¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
                parallel_capable_strategies = []
                for strategy in level_strategies:
                    strategy_profile = self.config.get('strategy_profiles', {}).get(strategy, {})
                    if strategy_profile.get('parallel_capable', True):
                        parallel_capable_strategies.append(strategy)
                
                if len(parallel_capable_strategies) >= self.config.get('dependency_management', {}).get('parallel_execution_threshold', 2):
                    parallel_groups.append(parallel_capable_strategies)
                else:
                    # ä¸¦åˆ—å®Ÿè¡Œã«é©ã•ãªã„å ´åˆã¯å€‹åˆ¥å®Ÿè¡Œ
                    for strategy in level_strategies:
                        parallel_groups.append([strategy])
            else:
                parallel_groups.append(list(level_strategies))
        
        return parallel_groups
    
    def _optimize_data_flow(self, execution_graph: ExecutionGraph) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–"""
        optimization = {
            'shared_data_optimization': {},
            'data_caching_recommendations': [],
            'memory_usage_estimation': {}
        }
        
        if not self.config.get('dependency_management', {}).get('data_sharing_optimization', True):
            return optimization
        
        # å…±æœ‰ãƒ‡ãƒ¼ã‚¿æœ€é©åŒ–
        data_usage_count = defaultdict(int)
        for node in execution_graph.nodes:
            for data_key in node.data_inputs:
                data_usage_count[data_key] += 1
        
        # å¤šãä½¿ç”¨ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ¨å¥¨
        for data_key, usage_count in data_usage_count.items():
            if usage_count > 2:
                optimization['data_caching_recommendations'].append({
                    'data_key': data_key,
                    'usage_count': usage_count,
                    'recommendation': 'ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¦å†åˆ©ç”¨ã‚’æœ€é©åŒ–'
                })
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¨å®š
        for data_key in execution_graph.shared_data_keys:
            # ç°¡å˜ãªæ¨å®šï¼ˆå®Ÿéš›ã«ã¯ãƒ‡ãƒ¼ã‚¿å‹ã‚„ã‚µã‚¤ã‚ºã‚’è€ƒæ…®ï¼‰
            estimated_size_mb = 10  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¨å®šå€¤
            optimization['memory_usage_estimation'][data_key] = estimated_size_mb
        
        optimization['shared_data_optimization'] = {
            'total_shared_data_keys': len(execution_graph.shared_data_keys),
            'high_usage_data_keys': len(optimization['data_caching_recommendations']),
            'estimated_total_memory_mb': sum(optimization['memory_usage_estimation'].values())
        }
        
        return optimization
    
    def _calculate_critical_path_duration(self, execution_graph: ExecutionGraph) -> float:
        """ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹å®Ÿè¡Œæ™‚é–“è¨ˆç®—"""
        if not execution_graph.nodes:
            return 0.0
        
        # å„ãƒãƒ¼ãƒ‰ã®æœ€æ—©é–‹å§‹æ™‚é–“ã¨æœ€é…çµ‚äº†æ™‚é–“ã‚’è¨ˆç®—
        node_durations = {}
        for node in execution_graph.nodes:
            node_durations[node.get_node_id()] = node.estimated_duration
        
        # æœ€é•·ãƒ‘ã‚¹è¨ˆç®—ï¼ˆDAGã®å ´åˆï¼‰
        try:
            longest_path = nx.dag_longest_path(self.dependency_graph, weight='estimated_duration')
            critical_path_duration = sum(node_durations.get(node_id, 0) for node_id in longest_path)
        except:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã™ã¹ã¦ã®ãƒãƒ¼ãƒ‰ã®åˆè¨ˆå®Ÿè¡Œæ™‚é–“
            critical_path_duration = sum(node.estimated_duration for node in execution_graph.nodes)
        
        return critical_path_duration
    
    def _generate_optimization_suggestions(
        self, 
        execution_graph: ExecutionGraph, 
        critical_path_duration: float
    ) -> List[str]:
        """æœ€é©åŒ–ææ¡ˆç”Ÿæˆ"""
        suggestions = []
        
        # ä¸¦åˆ—åŒ–ææ¡ˆ
        if len(execution_graph.execution_levels) > 3:
            suggestions.append("è¤‡æ•°ã®å®Ÿè¡Œãƒ¬ãƒ™ãƒ«ãŒã‚ã‚Šã¾ã™ã€‚ä¸¦åˆ—å®Ÿè¡Œã§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™")
        
        # ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹æœ€é©åŒ–
        if critical_path_duration > 120:  # 2åˆ†ä»¥ä¸Š
            suggestions.append("ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ãƒ‘ã‚¹ãŒé•·ã„ãŸã‚ã€ãƒœãƒˆãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã®æœ€é©åŒ–ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–
        if len(execution_graph.shared_data_keys) > 10:
            suggestions.append("å…±æœ‰ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ¼ãŒå¤šã„ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®çµ±åˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # ä¾å­˜é–¢ä¿‚ç°¡ç´ åŒ–
        if len(execution_graph.edges) > len(execution_graph.nodes) * 1.5:
            suggestions.append("ä¾å­˜é–¢ä¿‚ãŒè¤‡é›‘ã§ã™ã€‚ä¸è¦ãªä¾å­˜é–¢ä¿‚ã®å‰Šæ¸›ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        return suggestions
    
    def validate_execution_readiness(self, strategies: List[str]) -> Dict[str, Any]:
        """å®Ÿè¡Œæº–å‚™çŠ¶æ³æ¤œè¨¼"""
        validation_result = {
            'ready': True,
            'issues': [],
            'warnings': [],
            'dependency_status': {},
            'data_availability': {}
        }
        
        try:
            # ä¾å­˜é–¢ä¿‚è§£æ±º
            resolution = self.resolve_dependencies(strategies)
            
            # ä¾å­˜é–¢ä¿‚çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
            for dependency in resolution.resolved_dependencies:
                dep_id = dependency.get_dependency_id()
                
                if dependency.dependency_type == DependencyType.DATA:
                    # ãƒ‡ãƒ¼ã‚¿ä¾å­˜é–¢ä¿‚ã®å ´åˆã€ãƒ‡ãƒ¼ã‚¿åˆ©ç”¨å¯èƒ½æ€§ãƒã‚§ãƒƒã‚¯
                    if dependency.data_key:
                        available = self.data_flow_tracker.check_data_availability([dependency.data_key])
                        validation_result['data_availability'][dependency.data_key] = available.get(dependency.data_key, False)
                        
                        if not available.get(dependency.data_key, False):
                            if dependency.is_critical:
                                validation_result['issues'].append(
                                    f"Critical data '{dependency.data_key}' not available for {dependency.target_strategy}"
                                )
                                validation_result['ready'] = False
                            else:
                                validation_result['warnings'].append(
                                    f"Optional data '{dependency.data_key}' not available for {dependency.target_strategy}"
                                )
                
                validation_result['dependency_status'][dep_id] = DependencyStatus.SATISFIED.value
            
            # ãƒªã‚½ãƒ¼ã‚¹è¦æ±‚æ¤œè¨¼
            total_cpu_requirement = 0
            total_memory_requirement = 0
            
            for strategy in strategies:
                strategy_profile = self.config.get('strategy_profiles', {}).get(strategy, {})
                resource_req = strategy_profile.get('resource_requirements', {})
                
                total_cpu_requirement += resource_req.get('cpu', 0.1)
                memory_str = str(resource_req.get('memory', '64MB')).replace('MB', '')
                total_memory_requirement += int(memory_str)
            
            # ç°¡å˜ãªãƒªã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
            if total_cpu_requirement > 2.0:  # CPUä½¿ç”¨ç‡200%ä»¥ä¸Š
                validation_result['warnings'].append(
                    f"é«˜CPUè¦æ±‚ ({total_cpu_requirement:.1f}) - å®Ÿè¡Œæ™‚é–“ãŒé•·ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )
            
            if total_memory_requirement > 4096:  # 4GBä»¥ä¸Š
                validation_result['warnings'].append(
                    f"é«˜ãƒ¡ãƒ¢ãƒªè¦æ±‚ ({total_memory_requirement}MB) - ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )
        
        except Exception as e:
            validation_result['ready'] = False
            validation_result['issues'].append(f"Dependency resolution failed: {str(e)}")
        
        return validation_result
    
    def get_dependency_stats(self) -> Dict[str, Any]:
        """ä¾å­˜é–¢ä¿‚çµ±è¨ˆå–å¾—"""
        stats = {
            'total_resolutions': len(self.execution_history),
            'cache_entries': len(self.dependency_cache),
            'data_flow_stats': self.data_flow_tracker.get_data_flow_stats(),
            'graph_stats': {
                'nodes': len(self.dependency_graph.nodes),
                'edges': len(self.dependency_graph.edges),
                'is_acyclic': nx.is_directed_acyclic_graph(self.dependency_graph) if self.dependency_graph.nodes else True
            }
        }
        
        return stats

def create_demo_strategies() -> List[str]:
    """ãƒ‡ãƒ¢æˆ¦ç•¥ä½œæˆ"""
    return ["VWAPBounceStrategy", "GCStrategy", "BreakoutStrategy", "OpeningGapStrategy"]

if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    print("=" * 60)
    print("Strategy Dependency Resolver - Demo")
    print("=" * 60)
    
    try:
        # ãƒªã‚¾ãƒ«ãƒãƒ¼åˆæœŸåŒ–
        resolver = StrategyDependencyResolver()
        
        # ãƒ‡ãƒ¢æˆ¦ç•¥
        demo_strategies = create_demo_strategies()
        
        print(f"\nğŸ¯ Testing dependency resolution for strategies: {demo_strategies}")
        
        # ä¾å­˜é–¢ä¿‚è§£æ±º
        resolution = resolver.resolve_dependencies(demo_strategies)
        
        print(f"\nğŸ“Š Dependency Resolution Results:")
        print("-" * 50)
        print(f"Execution Order: {resolution.execution_order}")
        print(f"Parallel Groups: {resolution.parallel_groups}")
        print(f"Critical Path Duration: {resolution.critical_path_duration:.1f}s")
        print(f"Dependencies Resolved: {len(resolution.resolved_dependencies)}")
        
        # æœ€é©åŒ–ææ¡ˆ
        if resolution.optimization_suggestions:
            print(f"\nğŸ’¡ Optimization Suggestions:")
            for i, suggestion in enumerate(resolution.optimization_suggestions, 1):
                print(f"  {i}. {suggestion}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æœ€é©åŒ–
        data_flow = resolution.data_flow_optimization
        if data_flow.get('shared_data_optimization'):
            shared_opt = data_flow['shared_data_optimization']
            print(f"\nğŸ“ˆ Data Flow Optimization:")
            print(f"  Shared Data Keys: {shared_opt.get('total_shared_data_keys', 0)}")
            print(f"  High Usage Keys: {shared_opt.get('high_usage_data_keys', 0)}")
            print(f"  Est. Memory Usage: {shared_opt.get('estimated_total_memory_mb', 0)}MB")
        
        # å®Ÿè¡Œæº–å‚™æ¤œè¨¼
        print(f"\nğŸ” Testing execution readiness validation...")
        validation = resolver.validate_execution_readiness(demo_strategies)
        
        print(f"Execution Ready: {'âœ… Yes' if validation['ready'] else 'âŒ No'}")
        if validation['issues']:
            print(f"Issues: {len(validation['issues'])}")
            for issue in validation['issues']:
                print(f"  âš ï¸ {issue}")
        
        if validation['warnings']:
            print(f"Warnings: {len(validation['warnings'])}")
            for warning in validation['warnings']:
                print(f"  âš¡ {warning}")
        
        # çµ±è¨ˆæƒ…å ±
        stats = resolver.get_dependency_stats()
        print(f"\nğŸ“Š Dependency Statistics:")
        print(f"  Total Resolutions: {stats['total_resolutions']}")
        print(f"  Cache Entries: {stats['cache_entries']}")
        print(f"  Graph Nodes: {stats['graph_stats']['nodes']}")
        print(f"  Graph Edges: {stats['graph_stats']['edges']}")
        print(f"  Graph is Acyclic: {'âœ…' if stats['graph_stats']['is_acyclic'] else 'âŒ'}")
        
        print("\nâœ… Strategy Dependency Resolver demo completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
