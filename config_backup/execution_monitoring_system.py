"""
Module: Execution Monitoring System  
File: execution_monitoring_system.py
Description: 
  4-1-3ã€Œãƒãƒ«ãƒæˆ¦ç•¥åŒæ™‚å®Ÿè¡Œã®èª¿æ•´æ©Ÿèƒ½ã€
  å®Ÿè¡Œç›£è¦–ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æã‚·ã‚¹ãƒ†ãƒ 

Author: imega
Created: 2025-07-20
Modified: 2025-07-20

Functions:
  - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å®Ÿè¡Œç›£è¦–ãƒ»ç•°å¸¸æ¤œçŸ¥
  - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ»ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
  - ã‚¢ãƒ©ãƒ¼ãƒˆãƒ»é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
  - ç›£è¦–ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import os
import sys
import json
import time
import threading
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
import queue
from collections import deque, defaultdict
import statistics
from typing import Dict, List, Optional, Any, Callable, Set
from enum import Enum
from dataclasses import dataclass, asdict, field
from collections import defaultdict, deque
import statistics
import psutil
import queue
from concurrent.futures import Future

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from resource_allocation_engine import SystemLoad, ResourceAllocation
    from concurrent_execution_scheduler import ExecutionStatus, ExecutionResult
except ImportError:
    # ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ³ãƒ†ã‚¹ãƒˆç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    logger = logging.getLogger(__name__)
    logger.warning("Could not import project modules, using fallback definitions")
    
    class ExecutionStatus(Enum):
        PENDING = "pending"
        RUNNING = "running" 
        COMPLETED = "completed"
        FAILED = "failed"
        CANCELLED = "cancelled"
        TIMEOUT = "timeout"

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

class MonitoringLevel(Enum):
    """ç›£è¦–ãƒ¬ãƒ™ãƒ«"""
    BASIC = "basic"
    DETAILED = "detailed"
    COMPREHENSIVE = "comprehensive"

class AlertSeverity(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆé‡è¦åº¦"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

class MetricType(Enum):
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¨®åˆ¥"""
    PERFORMANCE = "performance"
    RESOURCE = "resource"
    ERROR = "error"
    THROUGHPUT = "throughput"

@dataclass
class MonitoringMetric:
    """ç›£è¦–ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""
    name: str
    value: float
    unit: str
    timestamp: datetime
    metric_type: MetricType
    strategy_name: Optional[str] = None
    additional_data: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['timestamp'] = self.timestamp.isoformat()
        result['metric_type'] = self.metric_type.value
        return result

@dataclass
class Alert:
    """ã‚¢ãƒ©ãƒ¼ãƒˆ"""
    alert_id: str
    title: str
    message: str
    severity: AlertSeverity
    timestamp: datetime
    strategy_name: Optional[str] = None
    metric_name: Optional[str] = None
    threshold_value: Optional[float] = None
    actual_value: Optional[float] = None
    acknowledged: bool = False
    resolved: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['severity'] = self.severity.value
        result['timestamp'] = self.timestamp.isoformat()
        return result

@dataclass
class PerformanceReport:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ"""
    report_id: str
    generated_at: datetime
    time_period: Tuple[datetime, datetime]
    strategies_analyzed: List[str]
    total_executions: int
    success_rate: float
    average_execution_time: float
    throughput_per_minute: float
    resource_efficiency: Dict[str, float]
    bottlenecks: List[str]
    recommendations: List[str]
    
    def to_dict(self) -> Dict[str, Any]:
        result = asdict(self)
        result['generated_at'] = self.generated_at.isoformat()
        result['time_period'] = [tp.isoformat() for tp in self.time_period]
        return result

class MetricCollector:
    """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.metrics_history: deque = deque(maxlen=config.get('monitoring', {}).get('max_metrics_history', 1000))
        self.real_time_metrics: Dict[str, MonitoringMetric] = {}
        self.collection_lock = threading.Lock()
        
    def collect_metric(self, metric: MonitoringMetric):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        with self.collection_lock:
            self.metrics_history.append(metric)
            self.real_time_metrics[metric.name] = metric
    
    def get_metrics_by_type(self, metric_type: MetricType, minutes: int = 5) -> List[MonitoringMetric]:
        """ç¨®åˆ¥åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        
        with self.collection_lock:
            return [
                metric for metric in self.metrics_history
                if metric.metric_type == metric_type and metric.timestamp > cutoff_time
            ]
    
    def get_strategy_metrics(self, strategy_name: str, minutes: int = 5) -> List[MonitoringMetric]:
        """æˆ¦ç•¥åˆ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        cutoff_time = datetime.now() - timedelta(minutes=minutes)
        
        with self.collection_lock:
            return [
                metric for metric in self.metrics_history
                if metric.strategy_name == strategy_name and metric.timestamp > cutoff_time
            ]
    
    def get_current_metrics(self) -> Dict[str, MonitoringMetric]:
        """ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        with self.collection_lock:
            return self.real_time_metrics.copy()

class AnomalyDetector:
    """ç•°å¸¸æ¤œçŸ¥å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.baseline_data: Dict[str, List[float]] = defaultdict(list)
        self.alert_thresholds = config.get('monitoring', {}).get('alert_thresholds', {})
        self.detection_lock = threading.Lock()
        
    def update_baseline(self, metric: MonitoringMetric):
        """ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ›´æ–°"""
        with self.detection_lock:
            key = f"{metric.strategy_name}:{metric.name}" if metric.strategy_name else metric.name
            self.baseline_data[key].append(metric.value)
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³å±¥æ­´é•·åˆ¶é™
            max_baseline_length = self.config.get('monitoring', {}).get('baseline_history_length', 100)
            if len(self.baseline_data[key]) > max_baseline_length:
                self.baseline_data[key].pop(0)
    
    def detect_anomaly(self, metric: MonitoringMetric) -> Optional[Alert]:
        """ç•°å¸¸æ¤œçŸ¥"""
        key = f"{metric.strategy_name}:{metric.name}" if metric.strategy_name else metric.name
        
        # é–¾å€¤ãƒ™ãƒ¼ã‚¹æ¤œçŸ¥
        threshold_alert = self._check_threshold_anomaly(metric)
        if threshold_alert:
            return threshold_alert
        
        # çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥
        statistical_alert = self._check_statistical_anomaly(metric, key)
        if statistical_alert:
            return statistical_alert
        
        return None
    
    def _check_threshold_anomaly(self, metric: MonitoringMetric) -> Optional[Alert]:
        """é–¾å€¤ãƒ™ãƒ¼ã‚¹ç•°å¸¸æ¤œçŸ¥"""
        thresholds = self.alert_thresholds.get(metric.name, {})
        
        # ä¸Šé™é–¾å€¤ãƒã‚§ãƒƒã‚¯
        upper_threshold = thresholds.get('upper')
        if upper_threshold and metric.value > upper_threshold:
            severity = AlertSeverity.CRITICAL if metric.value > upper_threshold * 1.5 else AlertSeverity.WARNING
            
            return Alert(
                alert_id=f"threshold_{metric.name}_{int(time.time())}",
                title=f"{metric.name} ä¸Šé™é–¾å€¤è¶…é",
                message=f"{metric.name} ãŒé–¾å€¤ {upper_threshold} ã‚’è¶…éã—ã¾ã—ãŸ (å®Ÿéš›å€¤: {metric.value})",
                severity=severity,
                timestamp=datetime.now(),
                strategy_name=metric.strategy_name,
                metric_name=metric.name,
                threshold_value=upper_threshold,
                actual_value=metric.value
            )
        
        # ä¸‹é™é–¾å€¤ãƒã‚§ãƒƒã‚¯
        lower_threshold = thresholds.get('lower')
        if lower_threshold and metric.value < lower_threshold:
            severity = AlertSeverity.WARNING if metric.value > lower_threshold * 0.5 else AlertSeverity.ERROR
            
            return Alert(
                alert_id=f"threshold_{metric.name}_{int(time.time())}",
                title=f"{metric.name} ä¸‹é™é–¾å€¤æœªé”",
                message=f"{metric.name} ãŒé–¾å€¤ {lower_threshold} ã‚’ä¸‹å›ã‚Šã¾ã—ãŸ (å®Ÿéš›å€¤: {metric.value})",
                severity=severity,
                timestamp=datetime.now(),
                strategy_name=metric.strategy_name,
                metric_name=metric.name,
                threshold_value=lower_threshold,
                actual_value=metric.value
            )
        
        return None
    
    def _check_statistical_anomaly(self, metric: MonitoringMetric, key: str) -> Optional[Alert]:
        """çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥"""
        with self.detection_lock:
            if key not in self.baseline_data or len(self.baseline_data[key]) < 10:
                return None  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ä¸è¶³
            
            baseline_values = self.baseline_data[key]
            mean_value = statistics.mean(baseline_values)
            std_value = statistics.stdev(baseline_values)
            
            # Z-scoreè¨ˆç®—
            if std_value > 0:
                z_score = abs(metric.value - mean_value) / std_value
                
                # çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥ï¼ˆZ-score > 2.5ã§ç•°å¸¸ã¨åˆ¤å®šï¼‰
                if z_score > 2.5:
                    severity = AlertSeverity.WARNING if z_score < 3.5 else AlertSeverity.ERROR
                    
                    return Alert(
                        alert_id=f"statistical_{metric.name}_{int(time.time())}",
                        title=f"{metric.name} çµ±è¨ˆçš„ç•°å¸¸æ¤œçŸ¥",
                        message=f"{metric.name} ã®å€¤ãŒçµ±è¨ˆçš„ã«ç•°å¸¸ã§ã™ (Z-score: {z_score:.2f}, å®Ÿéš›å€¤: {metric.value}, å¹³å‡å€¤: {mean_value:.2f})",
                        severity=severity,
                        timestamp=datetime.now(),
                        strategy_name=metric.strategy_name,
                        metric_name=metric.name,
                        threshold_value=mean_value + 2.5 * std_value,
                        actual_value=metric.value
                    )
        
        return None

class AlertManager:
    """ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.active_alerts: Dict[str, Alert] = {}
        self.alert_history: List[Alert] = []
        self.alert_subscribers: List[Callable[[Alert], None]] = []
        self.alert_lock = threading.Lock()
        
    def add_alert_subscriber(self, callback: Callable[[Alert], None]):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥è³¼èª­è€…è¿½åŠ """
        with self.alert_lock:
            self.alert_subscribers.append(callback)
    
    def raise_alert(self, alert: Alert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿ"""
        with self.alert_lock:
            self.active_alerts[alert.alert_id] = alert
            self.alert_history.append(alert)
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´é•·åˆ¶é™
            max_history = self.config.get('monitoring', {}).get('max_alert_history', 500)
            if len(self.alert_history) > max_history:
                self.alert_history.pop(0)
        
        # è³¼èª­è€…é€šçŸ¥
        for subscriber in self.alert_subscribers:
            try:
                subscriber(alert)
            except Exception as e:
                logger.error(f"Alert subscriber error: {e}")
        
        logger.warning(f"Alert raised: {alert.title} ({alert.severity.value})")
    
    def acknowledge_alert(self, alert_id: str) -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª"""
        with self.alert_lock:
            if alert_id in self.active_alerts:
                self.active_alerts[alert_id].acknowledged = True
                return True
            return False
    
    def resolve_alert(self, alert_id: str) -> bool:
        """ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±º"""
        with self.alert_lock:
            if alert_id in self.active_alerts:
                alert = self.active_alerts[alert_id]
                alert.resolved = True
                alert.acknowledged = True
                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆã‹ã‚‰å‰Šé™¤
                del self.active_alerts[alert_id]
                return True
            return False
    
    def get_active_alerts(self, severity: Optional[AlertSeverity] = None) -> List[Alert]:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆå–å¾—"""
        with self.alert_lock:
            alerts = list(self.active_alerts.values())
            if severity:
                alerts = [alert for alert in alerts if alert.severity == severity]
            return sorted(alerts, key=lambda a: a.timestamp, reverse=True)
    
    def get_alert_statistics(self) -> Dict[str, Any]:
        """ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ"""
        with self.alert_lock:
            total_alerts = len(self.alert_history)
            active_count = len(self.active_alerts)
            
            # é‡è¦åº¦åˆ¥çµ±è¨ˆ
            severity_counts = defaultdict(int)
            for alert in self.alert_history:
                severity_counts[alert.severity.value] += 1
            
            # æˆ¦ç•¥åˆ¥çµ±è¨ˆ
            strategy_counts = defaultdict(int)
            for alert in self.alert_history:
                if alert.strategy_name:
                    strategy_counts[alert.strategy_name] += 1
            
            return {
                'total_alerts': total_alerts,
                'active_alerts': active_count,
                'severity_distribution': dict(severity_counts),
                'strategy_distribution': dict(strategy_counts),
                'resolution_rate': (total_alerts - active_count) / total_alerts if total_alerts > 0 else 1.0
            }

class PerformanceAnalyzer:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.execution_history: List[ExecutionResult] = []
        self.analysis_lock = threading.Lock()
        
    def record_execution(self, result: ExecutionResult):
        """å®Ÿè¡Œçµæœè¨˜éŒ²"""
        with self.analysis_lock:
            self.execution_history.append(result)
            
            # å±¥æ­´é•·åˆ¶é™
            max_history = self.config.get('monitoring', {}).get('max_execution_history', 1000)
            if len(self.execution_history) > max_history:
                self.execution_history.pop(0)
    
    def generate_performance_report(self, time_range_minutes: int = 60) -> PerformanceReport:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=time_range_minutes)
        
        with self.analysis_lock:
            # æœŸé–“å†…ã®å®Ÿè¡Œçµæœãƒ•ã‚£ãƒ«ã‚¿
            period_results = [
                result for result in self.execution_history
                if result.start_time and start_time <= result.start_time <= end_time
            ]
            
            if not period_results:
                return self._create_empty_report(start_time, end_time)
            
            # çµ±è¨ˆè¨ˆç®—
            strategies_analyzed = list(set(result.strategy_name for result in period_results))
            total_executions = len(period_results)
            
            # æˆåŠŸç‡è¨ˆç®—
            successful_executions = sum(1 for result in period_results if result.status == ExecutionStatus.COMPLETED)
            success_rate = successful_executions / total_executions if total_executions > 0 else 0.0
            
            # å¹³å‡å®Ÿè¡Œæ™‚é–“
            execution_times = [result.execution_time for result in period_results if result.execution_time > 0]
            average_execution_time = statistics.mean(execution_times) if execution_times else 0.0
            
            # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆè¨ˆç®—ï¼ˆ1åˆ†ã‚ãŸã‚Šã®å®Ÿè¡Œæ•°ï¼‰
            throughput_per_minute = total_executions / time_range_minutes if time_range_minutes > 0 else 0.0
            
            # ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§åˆ†æ
            resource_efficiency = self._analyze_resource_efficiency(period_results)
            
            # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
            bottlenecks = self._identify_bottlenecks(period_results)
            
            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self._generate_recommendations(
                period_results, success_rate, average_execution_time, throughput_per_minute
            )
            
            report = PerformanceReport(
                report_id=f"perf_report_{int(time.time())}",
                generated_at=datetime.now(),
                time_period=(start_time, end_time),
                strategies_analyzed=strategies_analyzed,
                total_executions=total_executions,
                success_rate=success_rate,
                average_execution_time=average_execution_time,
                throughput_per_minute=throughput_per_minute,
                resource_efficiency=resource_efficiency,
                bottlenecks=bottlenecks,
                recommendations=recommendations
            )
            
            return report
    
    def _create_empty_report(self, start_time: datetime, end_time: datetime) -> PerformanceReport:
        """ç©ºã®ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ"""
        return PerformanceReport(
            report_id=f"perf_report_empty_{int(time.time())}",
            generated_at=datetime.now(),
            time_period=(start_time, end_time),
            strategies_analyzed=[],
            total_executions=0,
            success_rate=0.0,
            average_execution_time=0.0,
            throughput_per_minute=0.0,
            resource_efficiency={},
            bottlenecks=[],
            recommendations=["å®Ÿè¡Œãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ã‚ˆã‚Šå¤šãã®å®Ÿè¡Œã‚’è¡Œã£ãŸå¾Œã«å†åˆ†æã—ã¦ãã ã•ã„ã€‚"]
        )
    
    def _analyze_resource_efficiency(self, results: List[ExecutionResult]) -> Dict[str, float]:
        """ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡æ€§åˆ†æ"""
        efficiency = {}
        
        # å®Ÿè¡Œæ™‚é–“åŠ¹ç‡æ€§ï¼ˆçŸ­ã„ã»ã©è‰¯ã„ï¼‰
        execution_times = [r.execution_time for r in results if r.execution_time > 0]
        if execution_times:
            efficiency['execution_time_efficiency'] = 1.0 / statistics.mean(execution_times) if statistics.mean(execution_times) > 0 else 0.0
        
        # æˆåŠŸç‡åŠ¹ç‡æ€§
        success_count = sum(1 for r in results if r.status == ExecutionStatus.COMPLETED)
        efficiency['success_rate_efficiency'] = success_count / len(results) if results else 0.0
        
        return efficiency
    
    def _identify_bottlenecks(self, results: List[ExecutionResult]) -> List[str]:
        """ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š"""
        bottlenecks = []
        
        # å®Ÿè¡Œæ™‚é–“ãŒé•·ã„æˆ¦ç•¥
        strategy_times = defaultdict(list)
        for result in results:
            if result.execution_time > 0:
                strategy_times[result.strategy_name].append(result.execution_time)
        
        for strategy, times in strategy_times.items():
            avg_time = statistics.mean(times)
            if avg_time > 60:  # 1åˆ†ä»¥ä¸Š
                bottlenecks.append(f"{strategy}: å¹³å‡å®Ÿè¡Œæ™‚é–“ãŒé•·ã„ ({avg_time:.1f}s)")
        
        # å¤±æ•—ç‡ãŒé«˜ã„æˆ¦ç•¥
        strategy_failures = defaultdict(lambda: {'total': 0, 'failed': 0})
        for result in results:
            strategy_failures[result.strategy_name]['total'] += 1
            if result.status == ExecutionStatus.FAILED:
                strategy_failures[result.strategy_name]['failed'] += 1
        
        for strategy, stats in strategy_failures.items():
            failure_rate = stats['failed'] / stats['total'] if stats['total'] > 0 else 0
            if failure_rate > 0.2:  # 20%ä»¥ä¸Šã®å¤±æ•—ç‡
                bottlenecks.append(f"{strategy}: å¤±æ•—ç‡ãŒé«˜ã„ ({failure_rate:.1%})")
        
        return bottlenecks
    
    def _generate_recommendations(
        self, 
        results: List[ExecutionResult], 
        success_rate: float, 
        avg_execution_time: float, 
        throughput: float
    ) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        recommendations = []
        
        # æˆåŠŸç‡ã«åŸºã¥ãæ¨å¥¨
        if success_rate < 0.8:
            recommendations.append("æˆåŠŸç‡ãŒä½ã„ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®è¦‹ç›´ã—ã‚’æ¨å¥¨")
        
        # å®Ÿè¡Œæ™‚é–“ã«åŸºã¥ãæ¨å¥¨
        if avg_execution_time > 120:
            recommendations.append("å¹³å‡å®Ÿè¡Œæ™‚é–“ãŒé•·ã„ãŸã‚ã€ä¸¦åˆ—åŒ–ã¾ãŸã¯å‡¦ç†ã®æœ€é©åŒ–ã‚’æ¨å¥¨")
        
        # ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã«åŸºã¥ãæ¨å¥¨
        if throughput < 1.0:
            recommendations.append("ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒä½ã„ãŸã‚ã€ä¸¦è¡Œå®Ÿè¡Œæ•°ã®å¢—åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # æˆ¦ç•¥åˆ¥åˆ†æ
        strategy_performance = defaultdict(lambda: {'count': 0, 'success': 0, 'total_time': 0})
        for result in results:
            strategy_performance[result.strategy_name]['count'] += 1
            strategy_performance[result.strategy_name]['total_time'] += result.execution_time
            if result.status == ExecutionStatus.COMPLETED:
                strategy_performance[result.strategy_name]['success'] += 1
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒæ‚ªã„æˆ¦ç•¥ã®ç‰¹å®š
        for strategy, stats in strategy_performance.items():
            if stats['count'] >= 3:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«æ•°
                strategy_success_rate = stats['success'] / stats['count']
                avg_strategy_time = stats['total_time'] / stats['count']
                
                if strategy_success_rate < 0.7:
                    recommendations.append(f"{strategy}ã®æˆåŠŸç‡æ”¹å–„ãŒå¿…è¦")
                
                if avg_strategy_time > avg_execution_time * 1.5:
                    recommendations.append(f"{strategy}ã®å®Ÿè¡Œæ™‚é–“æœ€é©åŒ–ã‚’æ¨å¥¨")
        
        return recommendations

class ExecutionMonitoringSystem:
    """å®Ÿè¡Œç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, config_path: Optional[str] = None):
        """åˆæœŸåŒ–"""
        self.config = self._load_config(config_path)
        self.monitoring_level = MonitoringLevel(
            self.config.get('monitoring', {}).get('level', 'detailed')
        )
        
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.metric_collector = MetricCollector(self.config)
        self.anomaly_detector = AnomalyDetector(self.config)
        self.alert_manager = AlertManager(self.config)
        self.performance_analyzer = PerformanceAnalyzer(self.config)
        
        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        self.metric_queue = queue.Queue()
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆè³¼èª­è€…è¿½åŠ 
        self.alert_manager.add_alert_subscriber(self._default_alert_handler)
        
    def _load_config(self, config_path: Optional[str] = None) -> Dict[str, Any]:
        """è¨­å®šèª­ã¿è¾¼ã¿"""
        if config_path is None:
            config_path = os.path.join(os.path.dirname(__file__), 'coordination_config.json')
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"Failed to load config from {config_path}: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            "monitoring": {
                "level": "detailed",
                "collection_interval": 5.0,
                "max_metrics_history": 1000,
                "max_alert_history": 500,
                "max_execution_history": 1000,
                "baseline_history_length": 100,
                "alert_thresholds": {
                    "execution_time": {"upper": 300.0},
                    "memory_usage": {"upper": 0.8},
                    "cpu_usage": {"upper": 0.9},
                    "error_rate": {"upper": 0.2}
                }
            }
        }
    
    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()
        logger.info("Execution monitoring system started")
    
    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        self.monitoring_active = False
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_thread.join(timeout=5)
        logger.info("Execution monitoring system stopped")
    
    def _monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""
        collection_interval = self.config.get('monitoring', {}).get('collection_interval', 5.0)
        
        while self.monitoring_active:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
                self._collect_system_metrics()
                
                # ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡¦ç†
                while not self.metric_queue.empty():
                    try:
                        metric = self.metric_queue.get_nowait()
                        self._process_metric(metric)
                    except queue.Empty:
                        break
                
                time.sleep(collection_interval)
                
            except Exception as e:
                logger.error(f"Monitoring loop error: {e}")
                time.sleep(5)
    
    def _collect_system_metrics(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_metric = MonitoringMetric(
                name="cpu_usage",
                value=psutil.cpu_percent(interval=0.1) / 100.0,  # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
                unit="percentage",
                timestamp=datetime.now(),
                metric_type=MetricType.RESOURCE
            )
            self._process_metric(cpu_metric)
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            memory_metric = MonitoringMetric(
                name="memory_usage",
                value=memory.percent / 100.0,  # 0-1ã®ç¯„å›²ã«æ­£è¦åŒ–
                unit="percentage",
                timestamp=datetime.now(),
                metric_type=MetricType.RESOURCE
            )
            self._process_metric(memory_metric)
            
        except Exception as e:
            logger.error(f"System metrics collection error: {e}")
    
    def _process_metric(self, metric: MonitoringMetric):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡¦ç†"""
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
        self.metric_collector.collect_metric(metric)
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ›´æ–°
        self.anomaly_detector.update_baseline(metric)
        
        # ç•°å¸¸æ¤œçŸ¥
        alert = self.anomaly_detector.detect_anomaly(metric)
        if alert:
            self.alert_manager.raise_alert(alert)
    
    def _default_alert_handler(self, alert: Alert):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©"""
        logger.warning(f"[ALERT] {alert.title}: {alert.message}")
    
    def record_execution_start(self, strategy_name: str, task_id: str) -> str:
        """å®Ÿè¡Œé–‹å§‹è¨˜éŒ²"""
        start_metric = MonitoringMetric(
            name="execution_start",
            value=1.0,
            unit="count",
            timestamp=datetime.now(),
            metric_type=MetricType.PERFORMANCE,
            strategy_name=strategy_name,
            additional_data={'task_id': task_id}
        )
        
        self.metric_queue.put(start_metric)
        return f"execution_{strategy_name}_{int(time.time())}"
    
    def record_execution_completion(self, execution_result: ExecutionResult):
        """å®Ÿè¡Œå®Œäº†è¨˜éŒ²"""
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå™¨ã«è¨˜éŒ²
        self.performance_analyzer.record_execution(execution_result)
        
        # å®Ÿè¡Œæ™‚é–“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        if execution_result.execution_time > 0:
            time_metric = MonitoringMetric(
                name="execution_time",
                value=execution_result.execution_time,
                unit="seconds",
                timestamp=datetime.now(),
                metric_type=MetricType.PERFORMANCE,
                strategy_name=execution_result.strategy_name,
                additional_data={'task_id': execution_result.task_id, 'status': execution_result.status.value}
            )
            self.metric_queue.put(time_metric)
        
        # æˆåŠŸ/å¤±æ•—ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        success_metric = MonitoringMetric(
            name="execution_success",
            value=1.0 if execution_result.status == ExecutionStatus.COMPLETED else 0.0,
            unit="binary",
            timestamp=datetime.now(),
            metric_type=MetricType.PERFORMANCE,
            strategy_name=execution_result.strategy_name,
            additional_data={'task_id': execution_result.task_id, 'status': execution_result.status.value}
        )
        self.metric_queue.put(success_metric)
        
        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆå¤±æ•—æ™‚ï¼‰
        if execution_result.status == ExecutionStatus.FAILED:
            error_metric = MonitoringMetric(
                name="execution_error",
                value=1.0,
                unit="count",
                timestamp=datetime.now(),
                metric_type=MetricType.ERROR,
                strategy_name=execution_result.strategy_name,
                additional_data={'task_id': execution_result.task_id, 'error': execution_result.error}
            )
            self.metric_queue.put(error_metric)
    
    def get_real_time_metrics(self) -> Dict[str, Any]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        current_metrics = self.metric_collector.get_current_metrics()
        
        return {
            'system_metrics': {
                name: metric.to_dict() 
                for name, metric in current_metrics.items()
                if metric.metric_type == MetricType.RESOURCE
            },
            'performance_metrics': {
                name: metric.to_dict()
                for name, metric in current_metrics.items()
                if metric.metric_type == MetricType.PERFORMANCE
            },
            'active_alerts_count': len(self.alert_manager.get_active_alerts()),
            'timestamp': datetime.now().isoformat()
        }
    
    def generate_monitoring_report(self, time_range_minutes: int = 60) -> Dict[str, Any]:
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        performance_report = self.performance_analyzer.generate_performance_report(time_range_minutes)
        
        # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
        alert_stats = self.alert_manager.get_alert_statistics()
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ
        recent_metrics = []
        for metric_type in MetricType:
            type_metrics = self.metric_collector.get_metrics_by_type(metric_type, time_range_minutes)
            recent_metrics.extend(type_metrics)
        
        report = {
            'report_id': f"monitoring_report_{int(time.time())}",
            'generated_at': datetime.now().isoformat(),
            'time_range_minutes': time_range_minutes,
            'performance_analysis': performance_report.to_dict(),
            'alert_statistics': alert_stats,
            'metrics_summary': {
                'total_metrics_collected': len(recent_metrics),
                'metrics_by_type': {
                    metric_type.value: len(self.metric_collector.get_metrics_by_type(metric_type, time_range_minutes))
                    for metric_type in MetricType
                }
            },
            'system_health': self._assess_system_health()
        }
        
        return report
    
    def _assess_system_health(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹è©•ä¾¡"""
        current_metrics = self.metric_collector.get_current_metrics()
        active_alerts = self.alert_manager.get_active_alerts()
        
        # ãƒ˜ãƒ«ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆ0-100ï¼‰
        health_score = 100
        
        # CPUä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if 'cpu_usage' in current_metrics:
            cpu_usage = current_metrics['cpu_usage'].value
            if cpu_usage > 0.8:
                health_score -= 20
            elif cpu_usage > 0.6:
                health_score -= 10
        
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãƒã‚§ãƒƒã‚¯
        if 'memory_usage' in current_metrics:
            memory_usage = current_metrics['memory_usage'].value
            if memory_usage > 0.8:
                health_score -= 20
            elif memory_usage > 0.6:
                health_score -= 10
        
        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
        critical_alerts = len([a for a in active_alerts if a.severity == AlertSeverity.CRITICAL])
        error_alerts = len([a for a in active_alerts if a.severity == AlertSeverity.ERROR])
        
        health_score -= critical_alerts * 15
        health_score -= error_alerts * 10
        
        health_score = max(0, health_score)
        
        # ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹åˆ¤å®š
        if health_score >= 90:
            health_status = "excellent"
        elif health_score >= 70:
            health_status = "good"
        elif health_score >= 50:
            health_status = "fair"
        elif health_score >= 30:
            health_status = "poor"
        else:
            health_status = "critical"
        
        return {
            'health_score': health_score,
            'health_status': health_status,
            'active_alerts': len(active_alerts),
            'critical_alerts': critical_alerts,
            'error_alerts': error_alerts,
            'assessment_time': datetime.now().isoformat()
        }
    
    def get_strategy_performance_summary(self, strategy_name: str, minutes: int = 30) -> Dict[str, Any]:
        """æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼"""
        strategy_metrics = self.metric_collector.get_strategy_metrics(strategy_name, minutes)
        
        # å®Ÿè¡Œå›æ•°
        execution_count = len([m for m in strategy_metrics if m.name == "execution_start"])
        
        # æˆåŠŸç‡
        success_metrics = [m for m in strategy_metrics if m.name == "execution_success"]
        success_rate = sum(m.value for m in success_metrics) / len(success_metrics) if success_metrics else 0.0
        
        # å¹³å‡å®Ÿè¡Œæ™‚é–“
        time_metrics = [m for m in strategy_metrics if m.name == "execution_time"]
        avg_execution_time = sum(m.value for m in time_metrics) / len(time_metrics) if time_metrics else 0.0
        
        # ã‚¨ãƒ©ãƒ¼å›æ•°
        error_count = len([m for m in strategy_metrics if m.name == "execution_error"])
        
        return {
            'strategy_name': strategy_name,
            'time_period_minutes': minutes,
            'execution_count': execution_count,
            'success_rate': success_rate,
            'average_execution_time': avg_execution_time,
            'error_count': error_count,
            'summary_generated_at': datetime.now().isoformat()
        }
    
    def shutdown(self):
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³"""
        logger.info("Shutting down Execution Monitoring System...")
        self.stop_monitoring()
        logger.info("Execution Monitoring System shutdown complete")

# ãƒ‡ãƒ¢ç”¨ExecutionResultä½œæˆé–¢æ•°
def create_demo_execution_result(strategy_name: str, success: bool = True) -> ExecutionResult:
    """ãƒ‡ãƒ¢ç”¨å®Ÿè¡Œçµæœä½œæˆ"""
    import random
    
    status = ExecutionStatus.COMPLETED if success else ExecutionStatus.FAILED
    execution_time = random.uniform(5.0, 30.0)
    
    if not hasattr(create_demo_execution_result, 'ExecutionResult'):
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ExecutionResultå®šç¾©
        @dataclass
        class ExecutionResult:
            task_id: str
            strategy_name: str
            status: ExecutionStatus
            result: Any = None
            error: Optional[str] = None
            execution_time: float = 0.0
            start_time: Optional[datetime] = None
            end_time: Optional[datetime] = None
            retry_count: int = 0
            resource_usage: Dict[str, Any] = field(default_factory=dict)
            
            def to_dict(self) -> Dict[str, Any]:
                result = asdict(self)
                result['status'] = self.status.value
                result['start_time'] = self.start_time.isoformat() if self.start_time else None
                result['end_time'] = self.end_time.isoformat() if self.end_time else None
                return result
        
        create_demo_execution_result.ExecutionResult = ExecutionResult
    
    ExecutionResult = create_demo_execution_result.ExecutionResult
    
    return ExecutionResult(
        task_id=f"demo_{strategy_name}_{int(time.time())}",
        strategy_name=strategy_name,
        status=status,
        result={'pnl': random.uniform(-50, 100)} if success else None,
        error="Demo execution error" if not success else None,
        execution_time=execution_time,
        start_time=datetime.now() - timedelta(seconds=execution_time),
        end_time=datetime.now()
    )

if __name__ == "__main__":
    # ãƒ‡ãƒ¢å®Ÿè¡Œ
    print("=" * 60)
    print("Execution Monitoring System - Demo")
    print("=" * 60)
    
    try:
        # ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        monitor = ExecutionMonitoringSystem()
        
        # ç›£è¦–é–‹å§‹
        monitor.start_monitoring()
        print("ğŸ” Monitoring system started")
        
        # ãƒ‡ãƒ¢æˆ¦ç•¥å®Ÿè¡Œçµæœã‚’è¨˜éŒ²
        demo_strategies = ["VWAPBounceStrategy", "GCStrategy", "BreakoutStrategy"]
        
        print(f"\nğŸ“Š Recording execution results for {len(demo_strategies)} strategies...")
        for i, strategy in enumerate(demo_strategies):
            # å®Ÿè¡Œé–‹å§‹è¨˜éŒ²
            execution_id = monitor.record_execution_start(strategy, f"task_{i+1}")
            
            # ãƒ‡ãƒ¢å®Ÿè¡Œçµæœä½œæˆãƒ»è¨˜éŒ²
            success = (i % 4) != 0  # 25%å¤±æ•—ç‡
            result = create_demo_execution_result(strategy, success)
            monitor.record_execution_completion(result)
            
            status_emoji = "âœ…" if success else "âŒ"
            print(f"  {status_emoji} {strategy}: {result.execution_time:.1f}s")
            
            # å°‘ã—å¾…æ©Ÿï¼ˆç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãŒå‡¦ç†ã™ã‚‹æ™‚é–“ã‚’ç¢ºä¿ï¼‰
            time.sleep(0.5)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
        print(f"\nğŸ“ˆ Real-time Metrics:")
        real_time_metrics = monitor.get_real_time_metrics()
        
        if real_time_metrics['system_metrics']:
            print("  System Resources:")
            for name, metric in real_time_metrics['system_metrics'].items():
                print(f"    {name}: {metric['value']:.3f} {metric['unit']}")
        
        if real_time_metrics['performance_metrics']:
            print("  Performance:")
            for name, metric in real_time_metrics['performance_metrics'].items():
                print(f"    {name}: {metric['value']:.2f} {metric['unit']}")
        
        print(f"  Active Alerts: {real_time_metrics['active_alerts_count']}")
        
        # æˆ¦ç•¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼
        print(f"\nğŸ¯ Strategy Performance Summary:")
        for strategy in demo_strategies:
            summary = monitor.get_strategy_performance_summary(strategy, minutes=10)
            print(f"  {strategy}:")
            print(f"    Executions: {summary['execution_count']}")
            print(f"    Success Rate: {summary['success_rate']:.1%}")
            print(f"    Avg Time: {summary['average_execution_time']:.1f}s")
            print(f"    Errors: {summary['error_count']}")
        
        # ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        print(f"\nğŸ“‹ Generating monitoring report...")
        time.sleep(2)  # ã‚·ã‚¹ãƒ†ãƒ ãŒå‡¦ç†ã‚’å®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
        
        report = monitor.generate_monitoring_report(time_range_minutes=10)
        print(f"Report ID: {report['report_id']}")
        print(f"Metrics Collected: {report['metrics_summary']['total_metrics_collected']}")
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹
        health = report['system_health']
        print(f"System Health: {health['health_status'].upper()} ({health['health_score']}/100)")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
        perf = report['performance_analysis']
        print(f"Total Executions: {perf['total_executions']}")
        print(f"Success Rate: {perf['success_rate']:.1%}")
        print(f"Avg Execution Time: {perf['average_execution_time']:.1f}s")
        
        if perf['bottlenecks']:
            print("Bottlenecks Found:")
            for bottleneck in perf['bottlenecks']:
                print(f"  âš ï¸ {bottleneck}")
        
        if perf['recommendations']:
            print("Recommendations:")
            for rec in perf['recommendations']:
                print(f"  ğŸ’¡ {rec}")
        
        print("\nâœ… Execution Monitoring System demo completed successfully!")
        
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        if 'monitor' in locals():
            monitor.shutdown()
