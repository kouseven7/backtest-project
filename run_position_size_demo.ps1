# PowerShell Script: Run Position Size System Demo
# File: run_position_size_demo.ps1
# Description: 
#   3-3-2ã€Œå„æˆ¦ç•¥ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´æ©Ÿèƒ½ã€
#   çµ±åˆã‚·ã‚¹ãƒ†ãƒ ã®å‹•ä½œç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#
# Author: imega
# Created: 2025-07-20
# Modified: 2025-07-20
#
# Features:
# 1. ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
# 2. ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# 3. çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
# 4. çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
# 5. PowerShellç”¨ã‚³ãƒãƒ³ãƒ‰ï¼ˆ; ã‚’ä½¿ç”¨ï¼‰

param(
    [string]$Mode = "all",
    [switch]$SkipTests,
    [switch]$Verbose
)

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œè¨­å®š
$ErrorActionPreference = "Continue"
$ProgressPreference = "SilentlyContinue"

# ã‚«ãƒ©ãƒ¼å‡ºåŠ›è¨­å®š
$colors = @{
    'header' = 'Cyan'
    'success' = 'Green'
    'warning' = 'Yellow'
    'error' = 'Red'
    'info' = 'White'
}

function Write-ColorText {
    param($Text, $Color)
    Write-Host $Text -ForegroundColor $colors[$Color]
}

function Write-Section {
    param($Title)
    Write-Host ""
    Write-ColorText ("=" * 70) 'header'
    Write-ColorText $Title 'header'
    Write-ColorText ("=" * 70) 'header'
}

function Write-SubSection {
    param($Title)
    Write-Host ""
    Write-ColorText ("--- $Title ---") 'info'
}

function Test-FileExists {
    param($FilePath, $Description)
    if (Test-Path $FilePath) {
        Write-ColorText "âœ“ $Description - OK" 'success'
        return $true
    } else {
        Write-ColorText "âŒ $Description - Missing: $FilePath" 'error'
        return $false
    }
}

function Invoke-PythonCommand {
    param($Command, $Description)
    
    Write-ColorText "Running: $Description" 'info'
    if ($Verbose) {
        Write-ColorText "Command: $Command" 'info'
    }
    
    $start_time = Get-Date
    try {
        Invoke-Expression $Command
        $exit_code = $LASTEXITCODE
        $end_time = Get-Date
        $duration = ($end_time - $start_time).TotalSeconds
        
        if ($exit_code -eq 0) {
            Write-ColorText "âœ“ $Description completed successfully (${duration}s)" 'success'
            return $true
        } else {
            Write-ColorText "âŒ $Description failed (exit code: $exit_code)" 'error'
            return $false
        }
    } catch {
        $end_time = Get-Date
        $duration = ($end_time - $start_time).TotalSeconds
        Write-ColorText "âŒ $Description failed with exception: $($_.Exception.Message)" 'error'
        return $false
    }
}

function Test-SystemIntegrity {
    Write-Section "ğŸ” Position Size System Integrity Check"
    
    $required_files = @(
        @{Path="config/position_size_adjuster.py"; Description="Position Size Adjuster Module"},
        @{Path="config/position_sizing_config.json"; Description="Position Sizing Configuration"},
        @{Path="demo_position_size_adjuster.py"; Description="Demo Script"},
        @{Path="test_position_size_integration.py"; Description="Integration Test"}
    )
    
    $all_files_exist = $true
    
    foreach ($file in $required_files) {
        $exists = Test-FileExists $file.Path $file.Description
        $all_files_exist = $all_files_exist -and $exists
    }
    
    Write-SubSection "Dependency Check"
    
    $dependency_files = @(
        @{Path="config/portfolio_weight_calculator.py"; Description="Portfolio Weight Calculator"},
        @{Path="config/strategy_scoring_model.py"; Description="Strategy Scoring Model"},
        @{Path="config/signal_integrator.py"; Description="Signal Integrator"},
        @{Path="config/unified_trend_detector.py"; Description="Unified Trend Detector"},
        @{Path="config/risk_management.py"; Description="Risk Management"}
    )
    
    $dependency_count = 0
    foreach ($dep in $dependency_files) {
        if (Test-FileExists $dep.Path $dep.Description) {
            $dependency_count++
        }
    }
    
    Write-ColorText "Dependencies available: $dependency_count / $($dependency_files.Count)" 'info'
    
    if ($all_files_exist) {
        Write-ColorText "ğŸ‰ All required files are present!" 'success'
    } else {
        Write-ColorText "âš ï¸ Some required files are missing. System may not function properly." 'warning'
    }
    
    return $all_files_exist
}

function Run-BasicDemo {
    Write-Section "ğŸš€ Basic Position Size Demo"
    
    $success = Invoke-PythonCommand "python demo_position_size_adjuster.py" "Basic Position Size Demo"
    return $success
}

function Run-IntegrationTests {
    Write-Section "ğŸ§ª Integration Tests"
    
    if ($SkipTests) {
        Write-ColorText "Skipping integration tests (--SkipTests specified)" 'warning'
        return $true
    }
    
    $success = Invoke-PythonCommand "python test_position_size_integration.py" "Integration Test Suite"
    return $success
}

function Run-ConfigurationTest {
    Write-Section "âš™ï¸ Configuration Test"
    
    $python_code = @"
import json
from pathlib import Path

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ†ã‚¹ãƒˆ
try:
    with open('config/position_sizing_config.json', 'r') as f:
        config = json.load(f)
    
    print(f'âœ“ Configuration loaded successfully')
    print(f'  - Base position size: {config.get(\"base_position_size\", \"N/A\")}')
    print(f'  - Max position size: {config.get(\"max_position_size\", \"N/A\")}')
    print(f'  - Sizing method: {config.get(\"sizing_method\", \"N/A\")}')
    print(f'  - Market regime count: {len(config.get(\"market_regime_adjustments\", {}))}')
    
    # åŸºæœ¬çš„ãªè¨­å®šæ¤œè¨¼
    required_keys = ['base_position_size', 'max_position_size', 'min_position_size', 'sizing_method']
    missing_keys = [key for key in required_keys if key not in config]
    
    if missing_keys:
        print(f'âš ï¸ Missing configuration keys: {missing_keys}')
    else:
        print('âœ“ All required configuration keys present')
    
except Exception as e:
    print(f'âŒ Configuration test failed: {e}')
    exit(1)

print('Configuration test completed successfully!')
"@
    
    $python_code | Out-File -FilePath "temp_config_test.py" -Encoding utf8
    
    try {
        $success = Invoke-PythonCommand "python temp_config_test.py" "Configuration Loading Test"
        Remove-Item "temp_config_test.py" -Force -ErrorAction SilentlyContinue
        return $success
    } finally {
        Remove-Item "temp_config_test.py" -Force -ErrorAction SilentlyContinue
    }
}

function Run-ModuleImportTest {
    Write-Section "ğŸ“¦ Module Import Test"
    
    $python_code = @"
import sys
import traceback

modules_to_test = [
    'config.position_size_adjuster',
    'config.portfolio_weight_calculator',
    'config.strategy_scoring_model',
    'config.signal_integrator'
]

success_count = 0
total_count = len(modules_to_test)

for module_name in modules_to_test:
    try:
        __import__(module_name)
        print(f'âœ“ {module_name} imported successfully')
        success_count += 1
    except ImportError as e:
        print(f'âš ï¸ {module_name} import failed: {e}')
    except Exception as e:
        print(f'âŒ {module_name} unexpected error: {e}')

print(f'\nImport test results: {success_count}/{total_count} modules imported successfully')

if success_count >= total_count // 2:  # åŠæ•°ä»¥ä¸ŠæˆåŠŸã™ã‚Œã°OK
    print('Module import test passed!')
    exit(0)
else:
    print('Module import test failed!')
    exit(1)
"@
    
    $python_code | Out-File -FilePath "temp_import_test.py" -Encoding utf8
    
    try {
        $success = Invoke-PythonCommand "python temp_import_test.py" "Module Import Test"
        Remove-Item "temp_import_test.py" -Force -ErrorAction SilentlyContinue
        return $success
    } finally {
        Remove-Item "temp_import_test.py" -Force -ErrorAction SilentlyContinue
    }
}

function Run-PerformanceTest {
    Write-Section "âš¡ Performance Test"
    
    $python_code = @"
import time
import pandas as pd
import numpy as np
from datetime import datetime

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
print('Running position sizing performance test...')

# ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
np.random.seed(42)
test_data_sizes = [100, 500, 1000]
results = []

for size in test_data_sizes:
    start_time = time.time()
    
    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    data = pd.DataFrame({
        'close': np.random.random(size) * 100,
        'volume': np.random.randint(1000, 10000, size)
    })
    
    # åŸºæœ¬çš„ãªè¨ˆç®—ï¼ˆãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºè¨ˆç®—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
    returns = data['close'].pct_change().dropna()
    volatility = returns.std()
    position_size = min(0.05, max(0.01, 0.02 / max(volatility, 0.01)))
    
    end_time = time.time()
    duration = end_time - start_time
    results.append((size, duration))
    
    print(f'âœ“ Data size {size}: {duration:.3f}s, position_size: {position_size:.3f}')

avg_time = sum(r[1] for r in results) / len(results)
print(f'\nAverage processing time: {avg_time:.3f}s')

if avg_time < 1.0:  # 1ç§’ä»¥å†…
    print('âœ“ Performance test passed!')
else:
    print('âš ï¸ Performance may be slower than expected')

print('Performance test completed!')
"@
    
    $python_code | Out-File -FilePath "temp_performance_test.py" -Encoding utf8
    
    try {
        $success = Invoke-PythonCommand "python temp_performance_test.py" "Performance Test"
        Remove-Item "temp_performance_test.py" -Force -ErrorAction SilentlyContinue
        return $success
    } finally {
        Remove-Item "temp_performance_test.py" -Force -ErrorAction SilentlyContinue
    }
}

function Generate-TestReport {
    param($Results)
    
    Write-Section "ğŸ“Š Test Results Report"
    
    $timestamp = Get-Date -Format "yyyy-MM-dd HH:mm:ss"
    $total_tests = $Results.Keys.Count
    $passed_tests = ($Results.Values | Where-Object { $_ -eq $true }).Count
    $success_rate = if ($total_tests -gt 0) { [math]::Round(($passed_tests / $total_tests) * 100, 1) } else { 0 }
    
    Write-ColorText "Test Execution Report - $timestamp" 'header'
    Write-Host ""
    Write-ColorText "Overall Results:" 'info'
    Write-ColorText "  Total Tests: $total_tests" 'info'
    Write-ColorText "  Passed: $passed_tests" 'success'
    Write-ColorText "  Failed: $($total_tests - $passed_tests)" 'error'
    Write-ColorText "  Success Rate: $success_rate%" $(if ($success_rate -ge 80) { 'success' } elseif ($success_rate -ge 60) { 'warning' } else { 'error' })
    Write-Host ""
    
    Write-ColorText "Individual Test Results:" 'info'
    foreach ($test in $Results.GetEnumerator()) {
        $status = if ($test.Value) { "âœ“ PASS" } else { "âŒ FAIL" }
        $color = if ($test.Value) { 'success' } else { 'error' }
        Write-ColorText "  $($test.Key): $status" $color
    }
    
    Write-Host ""
    
    if ($success_rate -ge 80) {
        Write-ColorText "ğŸ‰ Position Size System is ready for deployment!" 'success'
    } elseif ($success_rate -ge 60) {
        Write-ColorText "âš ï¸ System is partially functional. Review failed tests." 'warning'
    } else {
        Write-ColorText "âŒ System requires significant fixes before deployment." 'error'
    }
    
    # ãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    $report_file = "position_size_test_report_$(Get-Date -Format 'yyyyMMdd_HHmmss').txt"
    $report_content = @"
Position Size System Test Report
Generated: $timestamp
Author: imega
Task: 3-3-2ã€Œå„æˆ¦ç•¥ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´æ©Ÿèƒ½ã€

SUMMARY:
Total Tests: $total_tests
Passed: $passed_tests
Failed: $($total_tests - $passed_tests)
Success Rate: $success_rate%

DETAILED RESULTS:
$($Results.GetEnumerator() | ForEach-Object { "$($_.Key): $(if ($_.Value) { 'PASS' } else { 'FAIL' })" } | Out-String)

STATUS:
$(if ($success_rate -ge 80) { 'READY FOR DEPLOYMENT' } elseif ($success_rate -ge 60) { 'PARTIALLY FUNCTIONAL' } else { 'REQUIRES FIXES' })

RECOMMENDATIONS:
$(if ($success_rate -ge 80) {
    '- System is functioning well and ready for production use
- Consider running periodic integration tests
- Monitor performance in production environment'
} elseif ($success_rate -ge 60) {
    '- Address failed test cases before full deployment
- Test specific failure scenarios in isolation
- Consider gradual rollout with monitoring'
} else {
    '- Review and fix critical system components
- Verify all dependencies are properly installed
- Check configuration files for correctness
- Consider rebuilding from known good state'
})
"@
    
    try {
        $report_content | Out-File -FilePath $report_file -Encoding utf8
        Write-ColorText "Report saved to: $report_file" 'info'
    } catch {
        Write-ColorText "Could not save report file: $($_.Exception.Message)" 'warning'
    }
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
function Main {
    Write-Section "ğŸ Position Size System Demo & Test Runner"
    Write-ColorText "Author: imega" 'info'
    Write-ColorText "Created: 2025-07-20" 'info'
    Write-ColorText "Task: 3-3-2ã€Œå„æˆ¦ç•¥ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´æ©Ÿèƒ½ã€" 'info'
    Write-ColorText "Mode: $Mode" 'info'
    if ($SkipTests) { Write-ColorText "Tests: Skipped" 'warning' }
    if ($Verbose) { Write-ColorText "Verbose: Enabled" 'info' }
    
    $results = @{}
    
    # ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
    $results["System Integrity"] = Test-SystemIntegrity
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ãŸå‡¦ç†
    switch ($Mode.ToLower()) {
        "integrity" {
            # å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯ã®ã¿
        }
        "demo" {
            $results["Basic Demo"] = Run-BasicDemo
        }
        "test" {
            $results["Integration Tests"] = Run-IntegrationTests
        }
        "config" {
            $results["Configuration Test"] = Run-ConfigurationTest
        }
        "import" {
            $results["Module Import Test"] = Run-ModuleImportTest
        }
        "performance" {
            $results["Performance Test"] = Run-PerformanceTest
        }
        "quick" {
            $results["Configuration Test"] = Run-ConfigurationTest
            $results["Module Import Test"] = Run-ModuleImportTest
        }
        "all" {
            $results["Configuration Test"] = Run-ConfigurationTest
            $results["Module Import Test"] = Run-ModuleImportTest
            $results["Basic Demo"] = Run-BasicDemo
            $results["Integration Tests"] = Run-IntegrationTests
            $results["Performance Test"] = Run-PerformanceTest
        }
        default {
            Write-ColorText "Unknown mode: $Mode" 'error'
            Write-ColorText "Available modes: integrity, demo, test, config, import, performance, quick, all" 'info'
            exit 1
        }
    }
    
    # çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    Generate-TestReport $results
    
    # å…¨ä½“çš„ãªæˆåŠŸåˆ¤å®š
    $overall_success = ($results.Values | Where-Object { $_ -eq $false }).Count -eq 0
    
    if ($overall_success) {
        Write-ColorText "`nğŸ‰ All tests passed! Position Size System is ready!" 'success'
        exit 0
    } else {
        Write-ColorText "`nâš ï¸ Some tests failed. Please review the results." 'warning'
        exit 1
    }
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½¿ç”¨æ–¹æ³•ã®è¡¨ç¤º
if ($args -contains "-help" -or $args -contains "--help") {
    Write-Host @"
Position Size System Demo & Test Runner

USAGE:
    .\run_position_size_demo.ps1 [-Mode <mode>] [-SkipTests] [-Verbose]

PARAMETERS:
    -Mode <mode>     : Test mode to run
                      â€¢ all         - Run all tests and demos (default)
                      â€¢ integrity   - System integrity check only
                      â€¢ demo        - Basic demo only
                      â€¢ test        - Integration tests only  
                      â€¢ config      - Configuration test only
                      â€¢ import      - Module import test only
                      â€¢ performance - Performance test only
                      â€¢ quick       - Config + Import tests only

    -SkipTests      : Skip integration tests (faster execution)
    -Verbose        : Show detailed command output

EXAMPLES:
    .\run_position_size_demo.ps1
    .\run_position_size_demo.ps1 -Mode quick
    .\run_position_size_demo.ps1 -Mode demo -Verbose
    .\run_position_size_demo.ps1 -Mode test -SkipTests

AUTHOR: imega
TASK: 3-3-2ã€Œå„æˆ¦ç•¥ã®ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´æ©Ÿèƒ½ã€
"@
    exit 0
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
Main
