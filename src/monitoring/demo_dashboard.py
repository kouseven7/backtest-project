"""
ãƒ•ã‚§ãƒ¼ã‚º3B ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§ã®å‹•ä½œã‚’ç¢ºèªã§ãã¾ã™ã€‚
"""

import asyncio
import time
import threading
import random
import json
from datetime import datetime, timedelta
from pathlib import Path
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(str(Path(__file__).parent.parent.parent))

from config.logger_config import setup_logger
from src.monitoring.dashboard import MonitoringDashboard, DashboardConfig, create_dashboard
from src.monitoring.metrics_collector import MetricsCollector
from src.monitoring.alert_manager import AlertManager, NotificationChannel, AlertLevel
from src.data.data_feed_integration import IntegratedDataFeedSystem, DataQualityMetrics, DataQualityLevel


class DashboardDemo:
    """ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        self.logger = setup_logger(__name__)
        self.is_running = False
        self.demo_thread = None
        
        # ãƒ‡ãƒ¢ç”¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.data_feed_system = None
        self.dashboard = None
        self.metrics_collector = None
        self.alert_manager = None
        
        # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨
        self.data_generators = []
        
    def setup_demo_environment(self):
        """ãƒ‡ãƒ¢ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        self.logger.info("Setting up demo environment...")
        
        try:
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            self.data_feed_system = IntegratedDataFeedSystem()
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†å™¨åˆæœŸåŒ–
            self.metrics_collector = MetricsCollector()
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†å™¨åˆæœŸåŒ–
            self.alert_manager = AlertManager()
            
            # ãƒ‡ãƒ¢ç”¨é€šçŸ¥ãƒãƒ£ãƒãƒ«è¨­å®š
            self._setup_demo_notifications()
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š
            dashboard_config = DashboardConfig(
                host="localhost",
                port=8080,
                auto_refresh_interval=3,
                enable_real_time_updates=True,
                chart_update_interval=2
            )
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ
            self.dashboard = create_dashboard(self.data_feed_system, dashboard_config)
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
            self.metrics_collector.add_metric_callback(self._on_metric_collected)
            
            self.logger.info("Demo environment setup completed")
            
        except Exception as e:
            self.logger.error(f"Error setting up demo environment: {e}")
            raise
            
    def _setup_demo_notifications(self):
        """ãƒ‡ãƒ¢ç”¨é€šçŸ¥è¨­å®š"""
        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«é€šçŸ¥ãƒãƒ£ãƒãƒ«ï¼ˆå®Ÿéš›ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã®ä»£ã‚ã‚Šï¼‰
        console_channel = NotificationChannel(
            channel_id="console_demo",
            name="ã‚³ãƒ³ã‚½ãƒ¼ãƒ«é€šçŸ¥ï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰",
            type="console",  # ã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¤ãƒ—
            config={},
            alert_levels=[AlertLevel.WARNING, AlertLevel.ERROR, AlertLevel.CRITICAL]
        )
        
        self.alert_manager.notification_manager.add_channel(console_channel)
        
        # ã‚«ã‚¹ã‚¿ãƒ é€šçŸ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¿½åŠ 
        original_send = self.alert_manager.notification_manager.send_alert_notification
        
        def demo_send_notification(alert):
            # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«é€šçŸ¥å†…å®¹è¡¨ç¤º
            self.logger.warning(f"ğŸš¨ ALERT: {alert.title} ({alert.level.value.upper()})")
            self.logger.warning(f"   Message: {alert.message}")
            self.logger.warning(f"   Source: {alert.source}")
            self.logger.warning(f"   Time: {alert.timestamp.strftime('%H:%M:%S')}")
            print("-" * 50)
            return True
            
        self.alert_manager.notification_manager.send_alert_notification = demo_send_notification
        
    def start_demo(self):
        """ãƒ‡ãƒ¢é–‹å§‹"""
        if self.is_running:
            self.logger.warning("Demo is already running")
            return
            
        self.logger.info("Starting dashboard demo...")
        print("\n" + "=" * 60)
        print("ãƒ•ã‚§ãƒ¼ã‚º3B ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ãƒ‡ãƒ¢")
        print("=" * 60)
        print(f"ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰URL: http://localhost:8080")
        print("ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°ã•ã‚Œã¾ã™")
        print("Ctrl+C ã§åœæ­¢")
        print("=" * 60 + "\n")
        
        try:
            self.is_running = True
            
            # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–‹å§‹
            self._start_data_generators()
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆç›£è¦–é–‹å§‹
            self.alert_manager.start_monitoring()
            
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é–‹å§‹ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
            dashboard_thread = threading.Thread(
                target=self._start_dashboard_background,
                daemon=True
            )
            dashboard_thread.start()
            
            # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¢ãƒ«ãƒ¼ãƒ—
            self._run_demo_loop()
            
        except KeyboardInterrupt:
            print("\n\nãƒ‡ãƒ¢ã‚’åœæ­¢ã—ã¦ã„ã¾ã™...")
            
        finally:
            self.stop_demo()
            
    def _start_dashboard_background(self):
        """ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰é–‹å§‹"""
        try:
            self.dashboard.start()
        except Exception as e:
            self.logger.error(f"Dashboard start error: {e}")
            
    def _start_data_generators(self):
        """ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå™¨é–‹å§‹"""
        # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆå™¨
        quality_generator = threading.Thread(
            target=self._generate_quality_data,
            daemon=True
        )
        quality_generator.start()
        self.data_generators.append(quality_generator)
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆå™¨
        performance_generator = threading.Thread(
            target=self._generate_performance_data,
            daemon=True
        )
        performance_generator.start()
        self.data_generators.append(performance_generator)
        
        # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆå™¨
        network_generator = threading.Thread(
            target=self._generate_network_data,
            daemon=True
        )
        network_generator.start()
        self.data_generators.append(network_generator)
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç”Ÿæˆå™¨
        cache_generator = threading.Thread(
            target=self._generate_cache_data,
            daemon=True
        )
        cache_generator.start()
        self.data_generators.append(cache_generator)
        
    def _generate_quality_data(self):
        """å“è³ªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        symbols = ["AAPL", "GOOGL", "MSFT", "TSLA", "AMZN"]
        
        while self.is_running:
            try:
                for symbol in symbols:
                    # ãƒ©ãƒ³ãƒ€ãƒ ãªå“è³ªã‚¹ã‚³ã‚¢ç”Ÿæˆï¼ˆæ™‚ã€…ä½å“è³ªã§ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿï¼‰
                    base_quality = 0.85
                    noise = random.gauss(0, 0.1)
                    
                    # æ™‚ã€…æ„å›³çš„ã«å“è³ªã‚’ä¸‹ã’ã‚‹
                    if random.random() < 0.1:  # 10%ã®ç¢ºç‡
                        base_quality = 0.6
                        
                    overall_score = max(0.1, min(1.0, base_quality + noise))
                    
                    # å„è»¸ã‚¹ã‚³ã‚¢
                    completeness = max(0.1, min(1.0, overall_score + random.gauss(0, 0.05)))
                    accuracy = max(0.1, min(1.0, overall_score + random.gauss(0, 0.05)))
                    timeliness = max(0.1, min(1.0, overall_score + random.gauss(0, 0.05)))
                    consistency = max(0.1, min(1.0, overall_score + random.gauss(0, 0.05)))
                    
                    # å“è³ªãƒ¬ãƒ™ãƒ«æ±ºå®š
                    if overall_score >= 0.9:
                        level = DataQualityLevel.EXCELLENT
                    elif overall_score >= 0.8:
                        level = DataQualityLevel.GOOD
                    elif overall_score >= 0.6:
                        level = DataQualityLevel.FAIR
                    elif overall_score >= 0.4:
                        level = DataQualityLevel.POOR
                    else:
                        level = DataQualityLevel.INVALID
                        
                    # å•é¡Œã¨ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
                    issues = []
                    recommendations = []
                    
                    if overall_score < 0.7:
                        issues.append("ãƒ‡ãƒ¼ã‚¿å“è³ªãŒä½ä¸‹ã—ã¦ã„ã¾ã™")
                        recommendations.append("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                        
                    if accuracy < 0.8:
                        issues.append("ãƒ‡ãƒ¼ã‚¿ç²¾åº¦ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
                        recommendations.append("ç•°å¸¸å€¤æ¤œå‡ºã‚’å¼·åŒ–ã—ã¦ãã ã•ã„")
                        
                    # å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ
                    quality_metrics = DataQualityMetrics(
                        symbol=symbol,
                        timestamp=datetime.now(),
                        completeness_score=completeness,
                        accuracy_score=accuracy,
                        timeliness_score=timeliness,
                        consistency_score=consistency,
                        overall_score=overall_score,
                        quality_level=level,
                        issues=issues,
                        recommendations=recommendations
                    )
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    self.metrics_collector.record_quality_metrics(quality_metrics)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ã«ã‚‚è¿½åŠ 
                    if symbol not in self.data_feed_system.quality_history:
                        self.data_feed_system.quality_history[symbol] = []
                    self.data_feed_system.quality_history[symbol].append(quality_metrics)
                    
                time.sleep(5)  # 5ç§’é–“éš”
                
            except Exception as e:
                self.logger.error(f"Error generating quality data: {e}")
                time.sleep(1)
                
    def _generate_performance_data(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        operations = ["data_fetch", "cache_get", "validation", "processing", "storage"]
        
        while self.is_running:
            try:
                for operation in operations:
                    # åŸºæœ¬å¿œç­”æ™‚é–“ï¼ˆæ“ä½œã«ã‚ˆã£ã¦ç•°ãªã‚‹ï¼‰
                    base_times = {
                        "data_fetch": 150,
                        "cache_get": 5,
                        "validation": 30,
                        "processing": 100,
                        "storage": 80
                    }
                    
                    base_time = base_times.get(operation, 50)
                    
                    # ãƒ©ãƒ³ãƒ€ãƒ ãªå¤‰å‹•è¿½åŠ 
                    duration = max(1, base_time + random.gauss(0, base_time * 0.3))
                    
                    # æ™‚ã€…é…å»¶ã‚’ç™ºç”Ÿ
                    if random.random() < 0.05:  # 5%ã®ç¢ºç‡
                        duration *= 5  # 5å€ã®é…å»¶
                        
                    # æˆåŠŸ/å¤±æ•—æ±ºå®š
                    success = random.random() > 0.02  # 2%ã®ã‚¨ãƒ©ãƒ¼ç‡
                    error_message = None if success else f"{operation} failed with timeout"
                    
                    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    self.metrics_collector.record_performance_metrics(
                        operation, duration, success, error_message
                    )
                    
                time.sleep(2)  # 2ç§’é–“éš”
                
            except Exception as e:
                self.logger.error(f"Error generating performance data: {e}")
                time.sleep(1)
                
    def _generate_network_data(self):
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        sources = ["yahoo_finance", "alpha_vantage", "internal_cache", "backup_source"]
        
        while self.is_running:
            try:
                for source in sources:
                    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
                    request_count = random.randint(5, 50)
                    
                    # å¿œç­”æ™‚é–“
                    base_response_time = {
                        "yahoo_finance": 120,
                        "alpha_vantage": 200,
                        "internal_cache": 10,
                        "backup_source": 300
                    }.get(source, 100)
                    
                    response_time = max(5, base_response_time + random.gauss(0, 30))
                    
                    # æˆåŠŸç‡
                    base_success_rate = 0.98
                    if random.random() < 0.1:  # æ™‚ã€…æˆåŠŸç‡ä½ä¸‹
                        base_success_rate = 0.85
                        
                    success_rate = max(0.5, min(1.0, base_success_rate + random.gauss(0, 0.05)))
                    
                    # ã‚¨ãƒ©ãƒ¼ãƒ»ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ•°
                    error_count = int(request_count * (1 - success_rate))
                    timeout_count = random.randint(0, max(1, error_count // 2))
                    
                    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    self.metrics_collector.record_network_metrics(
                        source, request_count, response_time, success_rate,
                        error_count, timeout_count
                    )
                    
                time.sleep(10)  # 10ç§’é–“éš”
                
            except Exception as e:
                self.logger.error(f"Error generating network data: {e}")
                time.sleep(1)
                
    def _generate_cache_data(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        cache_types = ["memory", "disk"]
        
        while self.is_running:
            try:
                for cache_type in cache_types:
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ€§èƒ½
                    base_hit_rate = 0.85 if cache_type == "memory" else 0.65
                    hit_rate = max(0.3, min(0.98, base_hit_rate + random.gauss(0, 0.1)))
                    
                    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°
                    total_requests = random.randint(100, 1000)
                    hit_count = int(total_requests * hit_rate)
                    miss_count = total_requests - hit_count
                    
                    # ã‚µã‚¤ã‚º
                    if cache_type == "memory":
                        size_bytes = random.randint(50*1024*1024, 200*1024*1024)  # 50-200MB
                        item_count = random.randint(500, 2000)
                    else:
                        size_bytes = random.randint(500*1024*1024, 2*1024*1024*1024)  # 500MB-2GB
                        item_count = random.randint(5000, 20000)
                        
                    eviction_count = random.randint(0, 10)
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
                    self.metrics_collector.record_cache_metrics(
                        cache_type, hit_count, miss_count, size_bytes,
                        item_count, eviction_count
                    )
                    
                time.sleep(8)  # 8ç§’é–“éš”
                
            except Exception as e:
                self.logger.error(f"Error generating cache data: {e}")
                time.sleep(1)
                
    def _run_demo_loop(self):
        """ãƒ‡ãƒ¢ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
        start_time = time.time()
        
        while self.is_running:
            try:
                # å®šæœŸçš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹è©•ä¾¡ï¼ˆã‚¢ãƒ©ãƒ¼ãƒˆç”Ÿæˆï¼‰
                metrics_summary = self.metrics_collector.get_all_metrics_summary(5)
                if metrics_summary:
                    self.alert_manager.evaluate_metrics(metrics_summary)
                    
                # çµ±è¨ˆæƒ…å ±è¡¨ç¤ºï¼ˆ30ç§’ã”ã¨ï¼‰
                if int(time.time() - start_time) % 30 == 0:
                    self._print_demo_status()
                    
                time.sleep(5)
                
            except Exception as e:
                self.logger.error(f"Error in demo loop: {e}")
                time.sleep(1)
                
    def _print_demo_status(self):
        """ãƒ‡ãƒ¢çŠ¶æ…‹è¡¨ç¤º"""
        try:
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ
            collection_stats = self.metrics_collector.collection_stats
            
            # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
            alert_stats = self.alert_manager.get_alert_stats()
            
            # ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            current_summary = self.metrics_collector.get_all_metrics_summary(5)
            
            print(f"\nğŸ“Š ãƒ‡ãƒ¢çŠ¶æ…‹ [{datetime.now().strftime('%H:%M:%S')}]")
            print(f"   åé›†ãƒ¡ãƒˆãƒªã‚¯ã‚¹: {collection_stats['total_collected']}")
            print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert_stats['active_count']}")
            print(f"   ç·ã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {alert_stats['total_generated']}")
            
            if current_summary.get('quality'):
                avg_quality = current_summary['quality'].get('overall', {}).get('mean', 0)
                print(f"   å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {avg_quality:.2f}")
                
            if current_summary.get('performance'):
                avg_response = current_summary['performance'].get('response_time', {}).get('mean', 0)
                print(f"   å¹³å‡å¿œç­”æ™‚é–“: {avg_response:.1f}ms")
                
        except Exception as e:
            self.logger.error(f"Error printing demo status: {e}")
            
    def _on_metric_collected(self, metric_type: str, metric_data):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã®è©³ç´°ãƒ­ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if metric_type == "quality" and hasattr(metric_data, 'overall_score'):
            if metric_data.overall_score < 0.7:
                self.logger.warning(
                    f"ğŸ” ä½å“è³ªæ¤œå‡º: {metric_data.symbol} = {metric_data.overall_score:.2f}"
                )
                
    def stop_demo(self):
        """ãƒ‡ãƒ¢åœæ­¢"""
        if not self.is_running:
            return
            
        self.logger.info("Stopping demo...")
        self.is_running = False
        
        try:
            # ã‚¢ãƒ©ãƒ¼ãƒˆç›£è¦–åœæ­¢
            if self.alert_manager:
                self.alert_manager.stop_monitoring()
                
            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆåœæ­¢
            if self.dashboard and self.dashboard.agent:
                self.dashboard.agent.stop()
                
            self.logger.info("Demo stopped successfully")
            
        except Exception as e:
            self.logger.error(f"Error stopping demo: {e}")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    demo = DashboardDemo()
    
    try:
        # ãƒ‡ãƒ¢ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        demo.setup_demo_environment()
        
        # ãƒ‡ãƒ¢é–‹å§‹
        demo.start_demo()
        
    except KeyboardInterrupt:
        print("\nãƒ‡ãƒ¢ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        
    except Exception as e:
        print(f"ãƒ‡ãƒ¢å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
    finally:
        demo.stop_demo()


if __name__ == "__main__":
    main()
